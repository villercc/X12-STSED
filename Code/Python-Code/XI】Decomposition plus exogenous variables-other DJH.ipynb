{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1353e14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集的长度： 324\n",
      "原始训练集的长度： 288\n",
      "原始测试集的长度： 36\n",
      "转为监督学习，训练集数据长度： 282\n",
      "转为监督学习，测试集数据长度： 30\n",
      "构造得到模型的输入数据(训练数据已有标签trainY):  (282, 2, 1, 3, 2) (30, 2, 1, 3, 2)\n",
      "Train on 282 samples\n",
      "Epoch 1/1000\n",
      "282/282 [==============================] - 5s 16ms/sample - loss: 0.2084\n",
      "Epoch 2/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.1929\n",
      "Epoch 3/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.1734\n",
      "Epoch 4/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.1494\n",
      "Epoch 5/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.1200\n",
      "Epoch 6/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0869\n",
      "Epoch 7/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0544\n",
      "Epoch 8/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0359\n",
      "Epoch 9/1000\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.036 - 0s 284us/sample - loss: 0.0363\n",
      "Epoch 10/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0343\n",
      "Epoch 11/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0339\n",
      "Epoch 12/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0337\n",
      "Epoch 13/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0334\n",
      "Epoch 14/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0333\n",
      "Epoch 15/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0331\n",
      "Epoch 16/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0328\n",
      "Epoch 17/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0326\n",
      "Epoch 18/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0323\n",
      "Epoch 19/1000\n",
      "282/282 [==============================] - 0s 252us/sample - loss: 0.0321\n",
      "Epoch 20/1000\n",
      "282/282 [==============================] - 0s 321us/sample - loss: 0.0319\n",
      "Epoch 21/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0317\n",
      "Epoch 22/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0314\n",
      "Epoch 23/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0312\n",
      "Epoch 24/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0306\n",
      "Epoch 25/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0303\n",
      "Epoch 26/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0299\n",
      "Epoch 27/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0294\n",
      "Epoch 28/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0289\n",
      "Epoch 29/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0285\n",
      "Epoch 30/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0278\n",
      "Epoch 31/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0270\n",
      "Epoch 32/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0262\n",
      "Epoch 33/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0253\n",
      "Epoch 34/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0244\n",
      "Epoch 35/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0232\n",
      "Epoch 36/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0218\n",
      "Epoch 37/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0202\n",
      "Epoch 38/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0183\n",
      "Epoch 39/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0168\n",
      "Epoch 40/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0154\n",
      "Epoch 41/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0144\n",
      "Epoch 42/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0133\n",
      "Epoch 43/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0129\n",
      "Epoch 44/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0127\n",
      "Epoch 45/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0125\n",
      "Epoch 46/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0129\n",
      "Epoch 47/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0125\n",
      "Epoch 48/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0120\n",
      "Epoch 49/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0116\n",
      "Epoch 50/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0120\n",
      "Epoch 51/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0120\n",
      "Epoch 52/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0113\n",
      "Epoch 53/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0111\n",
      "Epoch 54/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0109\n",
      "Epoch 55/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0108\n",
      "Epoch 56/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0107\n",
      "Epoch 57/1000\n",
      "282/282 [==============================] - 0s 381us/sample - loss: 0.0106\n",
      "Epoch 58/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0105\n",
      "Epoch 59/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0105\n",
      "Epoch 60/1000\n",
      "282/282 [==============================] - 0s 256us/sample - loss: 0.0107\n",
      "Epoch 61/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0112\n",
      "Epoch 62/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0105\n",
      "Epoch 63/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0103\n",
      "Epoch 64/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0101\n",
      "Epoch 65/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0096\n",
      "Epoch 66/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0095\n",
      "Epoch 67/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0095\n",
      "Epoch 68/1000\n",
      "282/282 [==============================] - 0s 267us/sample - loss: 0.0093\n",
      "Epoch 69/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0093\n",
      "Epoch 70/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0093\n",
      "Epoch 71/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0094\n",
      "Epoch 72/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0090\n",
      "Epoch 73/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0088\n",
      "Epoch 74/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0085\n",
      "Epoch 75/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0084\n",
      "Epoch 76/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0084\n",
      "Epoch 77/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0084\n",
      "Epoch 78/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0083\n",
      "Epoch 79/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0082\n",
      "Epoch 80/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0081\n",
      "Epoch 81/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0079\n",
      "Epoch 82/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0077\n",
      "Epoch 83/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0076\n",
      "Epoch 84/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0076\n",
      "Epoch 85/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0077\n",
      "Epoch 86/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0075\n",
      "Epoch 87/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0073\n",
      "Epoch 88/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0074\n",
      "Epoch 89/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0074\n",
      "Epoch 90/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0070\n",
      "Epoch 91/1000\n",
      "282/282 [==============================] - 0s 259us/sample - loss: 0.0069\n",
      "Epoch 92/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 328us/sample - loss: 0.0069\n",
      "Epoch 93/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0068\n",
      "Epoch 94/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0067\n",
      "Epoch 95/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0067\n",
      "Epoch 96/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0066\n",
      "Epoch 97/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0064\n",
      "Epoch 98/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0064\n",
      "Epoch 99/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0065\n",
      "Epoch 100/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0064\n",
      "Epoch 101/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0063\n",
      "Epoch 102/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0061\n",
      "Epoch 103/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0063\n",
      "Epoch 104/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0061\n",
      "Epoch 105/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0061\n",
      "Epoch 106/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0060\n",
      "Epoch 107/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0060\n",
      "Epoch 108/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0060\n",
      "Epoch 109/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0060\n",
      "Epoch 110/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0057\n",
      "Epoch 111/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0061\n",
      "Epoch 112/1000\n",
      "282/282 [==============================] - 0s 267us/sample - loss: 0.0059\n",
      "Epoch 113/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0059\n",
      "Epoch 114/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0058\n",
      "Epoch 115/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0056\n",
      "Epoch 116/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0057\n",
      "Epoch 117/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0057\n",
      "Epoch 118/1000\n",
      "282/282 [==============================] - 0s 270us/sample - loss: 0.0056\n",
      "Epoch 119/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0055\n",
      "Epoch 120/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0056\n",
      "Epoch 121/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0054\n",
      "Epoch 122/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0055\n",
      "Epoch 123/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0055\n",
      "Epoch 124/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0054\n",
      "Epoch 125/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0053\n",
      "Epoch 126/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0056\n",
      "Epoch 127/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0054\n",
      "Epoch 128/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0052\n",
      "Epoch 129/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0053\n",
      "Epoch 130/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0052\n",
      "Epoch 131/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0052\n",
      "Epoch 132/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0054\n",
      "Epoch 133/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0053\n",
      "Epoch 134/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0050\n",
      "Epoch 135/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0052\n",
      "Epoch 136/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0050\n",
      "Epoch 137/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0050\n",
      "Epoch 138/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0049\n",
      "Epoch 139/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0050\n",
      "Epoch 140/1000\n",
      "282/282 [==============================] - 0s 267us/sample - loss: 0.0050\n",
      "Epoch 141/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0049\n",
      "Epoch 142/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0050\n",
      "Epoch 143/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0048\n",
      "Epoch 144/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0048\n",
      "Epoch 145/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0050\n",
      "Epoch 146/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0048\n",
      "Epoch 147/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0050\n",
      "Epoch 148/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0051\n",
      "Epoch 149/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0050\n",
      "Epoch 150/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0051\n",
      "Epoch 151/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0053\n",
      "Epoch 152/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0052\n",
      "Epoch 153/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0053\n",
      "Epoch 154/1000\n",
      "282/282 [==============================] - 0s 365us/sample - loss: 0.0050\n",
      "Epoch 155/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0051\n",
      "Epoch 156/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0048\n",
      "Epoch 157/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0046\n",
      "Epoch 158/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0048\n",
      "Epoch 159/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0045\n",
      "Epoch 160/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0048\n",
      "Epoch 161/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0046\n",
      "Epoch 162/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0048\n",
      "Epoch 163/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0045\n",
      "Epoch 164/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0044\n",
      "Epoch 165/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0044\n",
      "Epoch 166/1000\n",
      "282/282 [==============================] - 0s 284us/sample - loss: 0.0044\n",
      "Epoch 167/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0050\n",
      "Epoch 168/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0044\n",
      "Epoch 169/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0043\n",
      "Epoch 170/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0045\n",
      "Epoch 171/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0043\n",
      "Epoch 172/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0043\n",
      "Epoch 173/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0042\n",
      "Epoch 174/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0043\n",
      "Epoch 175/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0043\n",
      "Epoch 176/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0042\n",
      "Epoch 177/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0042\n",
      "Epoch 178/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0043\n",
      "Epoch 179/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0041\n",
      "Epoch 180/1000\n",
      "282/282 [==============================] - 0s 270us/sample - loss: 0.0040\n",
      "Epoch 181/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0040\n",
      "Epoch 182/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0039\n",
      "Epoch 183/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0040\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0042\n",
      "Epoch 185/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0045\n",
      "Epoch 186/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0044\n",
      "Epoch 187/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0039\n",
      "Epoch 188/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0039\n",
      "Epoch 189/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0040\n",
      "Epoch 190/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0039\n",
      "Epoch 191/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0040\n",
      "Epoch 192/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0040\n",
      "Epoch 193/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0039\n",
      "Epoch 194/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0038\n",
      "Epoch 195/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0041\n",
      "Epoch 196/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0041\n",
      "Epoch 197/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0041\n",
      "Epoch 198/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0039\n",
      "Epoch 199/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0037\n",
      "Epoch 200/1000\n",
      "282/282 [==============================] - 0s 284us/sample - loss: 0.0038\n",
      "Epoch 201/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0037\n",
      "Epoch 202/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0038\n",
      "Epoch 203/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0036\n",
      "Epoch 204/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0036\n",
      "Epoch 205/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0036\n",
      "Epoch 206/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0036\n",
      "Epoch 207/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0037\n",
      "Epoch 208/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0035\n",
      "Epoch 209/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0035\n",
      "Epoch 210/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0035\n",
      "Epoch 211/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0035\n",
      "Epoch 212/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0035\n",
      "Epoch 213/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0035\n",
      "Epoch 214/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0037\n",
      "Epoch 215/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0040\n",
      "Epoch 216/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0035\n",
      "Epoch 217/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0035\n",
      "Epoch 218/1000\n",
      "282/282 [==============================] - 0s 335us/sample - loss: 0.0036\n",
      "Epoch 219/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0035\n",
      "Epoch 220/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0034\n",
      "Epoch 221/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0034\n",
      "Epoch 222/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0037\n",
      "Epoch 223/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0035\n",
      "Epoch 224/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0038\n",
      "Epoch 225/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0036\n",
      "Epoch 226/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0033\n",
      "Epoch 227/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0033\n",
      "Epoch 228/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0033\n",
      "Epoch 229/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0034\n",
      "Epoch 230/1000\n",
      "282/282 [==============================] - 0s 334us/sample - loss: 0.0033\n",
      "Epoch 231/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0033\n",
      "Epoch 232/1000\n",
      "282/282 [==============================] - 0s 268us/sample - loss: 0.0032\n",
      "Epoch 233/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0033\n",
      "Epoch 234/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0032\n",
      "Epoch 235/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0032\n",
      "Epoch 236/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0033\n",
      "Epoch 237/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0034\n",
      "Epoch 238/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0033\n",
      "Epoch 239/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0032\n",
      "Epoch 240/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0032\n",
      "Epoch 241/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0033\n",
      "Epoch 242/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0034\n",
      "Epoch 243/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0031\n",
      "Epoch 244/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0032\n",
      "Epoch 245/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0031\n",
      "Epoch 246/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0032\n",
      "Epoch 247/1000\n",
      "282/282 [==============================] - 0s 268us/sample - loss: 0.0034\n",
      "Epoch 248/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0033\n",
      "Epoch 249/1000\n",
      "282/282 [==============================] - 0s 335us/sample - loss: 0.0032\n",
      "Epoch 250/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0031\n",
      "Epoch 251/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0033\n",
      "Epoch 252/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0035\n",
      "Epoch 253/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0034\n",
      "Epoch 254/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0033\n",
      "Epoch 255/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0033\n",
      "Epoch 256/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0032\n",
      "Epoch 257/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0031\n",
      "Epoch 258/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0031\n",
      "Epoch 259/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0030\n",
      "Epoch 260/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0032\n",
      "Epoch 261/1000\n",
      "282/282 [==============================] - 0s 362us/sample - loss: 0.0032\n",
      "Epoch 262/1000\n",
      "282/282 [==============================] - 0s 347us/sample - loss: 0.0031\n",
      "Epoch 263/1000\n",
      "282/282 [==============================] - 0s 361us/sample - loss: 0.0031\n",
      "Epoch 264/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0031\n",
      "Epoch 265/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0033\n",
      "Epoch 266/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0035\n",
      "Epoch 267/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0032\n",
      "Epoch 268/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0030\n",
      "Epoch 269/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0031\n",
      "Epoch 270/1000\n",
      "282/282 [==============================] - 0s 357us/sample - loss: 0.0031\n",
      "Epoch 271/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0031\n",
      "Epoch 272/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0030\n",
      "Epoch 273/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0030\n",
      "Epoch 274/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0030\n",
      "Epoch 275/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0030\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0029\n",
      "Epoch 277/1000\n",
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0029\n",
      "Epoch 278/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0029\n",
      "Epoch 279/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0031\n",
      "Epoch 280/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0030\n",
      "Epoch 281/1000\n",
      "282/282 [==============================] - 0s 373us/sample - loss: 0.0030\n",
      "Epoch 282/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0030\n",
      "Epoch 283/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0030\n",
      "Epoch 284/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0030\n",
      "Epoch 285/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0032\n",
      "Epoch 286/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0031\n",
      "Epoch 287/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0030\n",
      "Epoch 288/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0029\n",
      "Epoch 289/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0029\n",
      "Epoch 290/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0029\n",
      "Epoch 291/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0028\n",
      "Epoch 292/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0029\n",
      "Epoch 293/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0029\n",
      "Epoch 294/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0030\n",
      "Epoch 295/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0032\n",
      "Epoch 296/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0033\n",
      "Epoch 297/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0029\n",
      "Epoch 298/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0029\n",
      "Epoch 299/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0029\n",
      "Epoch 300/1000\n",
      "282/282 [==============================] - 0s 339us/sample - loss: 0.0028\n",
      "Epoch 301/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0029\n",
      "Epoch 302/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0029\n",
      "Epoch 303/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0029\n",
      "Epoch 304/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0028\n",
      "Epoch 305/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0030\n",
      "Epoch 306/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0029\n",
      "Epoch 307/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0028\n",
      "Epoch 308/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0028\n",
      "Epoch 309/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0030\n",
      "Epoch 310/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0030\n",
      "Epoch 311/1000\n",
      "282/282 [==============================] - 0s 270us/sample - loss: 0.0029\n",
      "Epoch 312/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0027\n",
      "Epoch 313/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0028\n",
      "Epoch 314/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0029\n",
      "Epoch 315/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0028\n",
      "Epoch 316/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0028\n",
      "Epoch 317/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0028\n",
      "Epoch 318/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0029\n",
      "Epoch 319/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0028\n",
      "Epoch 320/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0028\n",
      "Epoch 321/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0029\n",
      "Epoch 322/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0029\n",
      "Epoch 323/1000\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.003 - 0s 295us/sample - loss: 0.0029\n",
      "Epoch 324/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0028\n",
      "Epoch 325/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0027\n",
      "Epoch 326/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0027\n",
      "Epoch 327/1000\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.002 - 0s 283us/sample - loss: 0.0027\n",
      "Epoch 328/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0028\n",
      "Epoch 329/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0028\n",
      "Epoch 330/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0027\n",
      "Epoch 331/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0027\n",
      "Epoch 332/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0028\n",
      "Epoch 333/1000\n",
      "282/282 [==============================] - 0s 270us/sample - loss: 0.0027\n",
      "Epoch 334/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0027\n",
      "Epoch 335/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0028\n",
      "Epoch 336/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0028\n",
      "Epoch 337/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0027\n",
      "Epoch 338/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0027\n",
      "Epoch 339/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0028\n",
      "Epoch 340/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0029\n",
      "Epoch 341/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0027\n",
      "Epoch 342/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0027\n",
      "Epoch 343/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0026\n",
      "Epoch 344/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0026\n",
      "Epoch 345/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0028\n",
      "Epoch 346/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0028\n",
      "Epoch 347/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0027\n",
      "Epoch 348/1000\n",
      "282/282 [==============================] - 0s 284us/sample - loss: 0.0027\n",
      "Epoch 349/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0026\n",
      "Epoch 350/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0028\n",
      "Epoch 351/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0027\n",
      "Epoch 352/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0026\n",
      "Epoch 353/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0031\n",
      "Epoch 354/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0027\n",
      "Epoch 355/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0026\n",
      "Epoch 356/1000\n",
      "282/282 [==============================] - 0s 284us/sample - loss: 0.0027\n",
      "Epoch 357/1000\n",
      "282/282 [==============================] - 0s 343us/sample - loss: 0.0025\n",
      "Epoch 358/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0026\n",
      "Epoch 359/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0027\n",
      "Epoch 360/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0026\n",
      "Epoch 361/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0028\n",
      "Epoch 362/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0025\n",
      "Epoch 363/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0026\n",
      "Epoch 364/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0029\n",
      "Epoch 365/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0027\n",
      "Epoch 366/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0026\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 351us/sample - loss: 0.0026\n",
      "Epoch 368/1000\n",
      "282/282 [==============================] - 0s 349us/sample - loss: 0.0025\n",
      "Epoch 369/1000\n",
      "282/282 [==============================] - 0s 349us/sample - loss: 0.0027\n",
      "Epoch 370/1000\n",
      "282/282 [==============================] - 0s 371us/sample - loss: 0.0029\n",
      "Epoch 371/1000\n",
      "282/282 [==============================] - 0s 361us/sample - loss: 0.0029\n",
      "Epoch 372/1000\n",
      "282/282 [==============================] - 0s 383us/sample - loss: 0.0030\n",
      "Epoch 373/1000\n",
      "282/282 [==============================] - 0s 388us/sample - loss: 0.0028\n",
      "Epoch 374/1000\n",
      "282/282 [==============================] - 0s 398us/sample - loss: 0.0026\n",
      "Epoch 375/1000\n",
      "282/282 [==============================] - 0s 370us/sample - loss: 0.0025\n",
      "Epoch 376/1000\n",
      "282/282 [==============================] - 0s 378us/sample - loss: 0.0026\n",
      "Epoch 377/1000\n",
      "282/282 [==============================] - 0s 372us/sample - loss: 0.0025\n",
      "Epoch 378/1000\n",
      "282/282 [==============================] - 0s 365us/sample - loss: 0.0027\n",
      "Epoch 379/1000\n",
      "282/282 [==============================] - 0s 411us/sample - loss: 0.0027\n",
      "Epoch 380/1000\n",
      "282/282 [==============================] - 0s 370us/sample - loss: 0.0027\n",
      "Epoch 381/1000\n",
      "282/282 [==============================] - 0s 368us/sample - loss: 0.0026\n",
      "Epoch 382/1000\n",
      "282/282 [==============================] - 0s 362us/sample - loss: 0.0028\n",
      "Epoch 383/1000\n",
      "282/282 [==============================] - 0s 377us/sample - loss: 0.0025\n",
      "Epoch 384/1000\n",
      "282/282 [==============================] - 0s 380us/sample - loss: 0.0025\n",
      "Epoch 385/1000\n",
      "282/282 [==============================] - 0s 355us/sample - loss: 0.0025\n",
      "Epoch 386/1000\n",
      "282/282 [==============================] - 0s 361us/sample - loss: 0.0025\n",
      "Epoch 387/1000\n",
      "282/282 [==============================] - 0s 358us/sample - loss: 0.0025\n",
      "Epoch 388/1000\n",
      "282/282 [==============================] - 0s 361us/sample - loss: 0.0026\n",
      "Epoch 389/1000\n",
      "282/282 [==============================] - 0s 369us/sample - loss: 0.0026\n",
      "Epoch 390/1000\n",
      "282/282 [==============================] - 0s 351us/sample - loss: 0.0025\n",
      "Epoch 391/1000\n",
      "282/282 [==============================] - 0s 379us/sample - loss: 0.0025\n",
      "Epoch 392/1000\n",
      "282/282 [==============================] - 0s 360us/sample - loss: 0.0024\n",
      "Epoch 393/1000\n",
      "282/282 [==============================] - 0s 375us/sample - loss: 0.0024\n",
      "Epoch 394/1000\n",
      "282/282 [==============================] - 0s 333us/sample - loss: 0.0025\n",
      "Epoch 395/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0027\n",
      "Epoch 396/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0031\n",
      "Epoch 397/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0029\n",
      "Epoch 398/1000\n",
      "282/282 [==============================] - 0s 347us/sample - loss: 0.0025\n",
      "Epoch 399/1000\n",
      "282/282 [==============================] - 0s 342us/sample - loss: 0.0025\n",
      "Epoch 400/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0025\n",
      "Epoch 401/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0026\n",
      "Epoch 402/1000\n",
      "282/282 [==============================] - 0s 347us/sample - loss: 0.0024\n",
      "Epoch 403/1000\n",
      "282/282 [==============================] - 0s 349us/sample - loss: 0.0024\n",
      "Epoch 404/1000\n",
      "282/282 [==============================] - 0s 347us/sample - loss: 0.0025\n",
      "Epoch 405/1000\n",
      "282/282 [==============================] - 0s 321us/sample - loss: 0.0025\n",
      "Epoch 406/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0024\n",
      "Epoch 407/1000\n",
      "282/282 [==============================] - 0s 326us/sample - loss: 0.0025\n",
      "Epoch 408/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0025\n",
      "Epoch 409/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0024\n",
      "Epoch 410/1000\n",
      "282/282 [==============================] - 0s 393us/sample - loss: 0.0025\n",
      "Epoch 411/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0026\n",
      "Epoch 412/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0025\n",
      "Epoch 413/1000\n",
      "282/282 [==============================] - 0s 379us/sample - loss: 0.0024\n",
      "Epoch 414/1000\n",
      "282/282 [==============================] - 0s 364us/sample - loss: 0.0025\n",
      "Epoch 415/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0025\n",
      "Epoch 416/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0025\n",
      "Epoch 417/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0024\n",
      "Epoch 418/1000\n",
      "282/282 [==============================] - 0s 362us/sample - loss: 0.0024\n",
      "Epoch 419/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0024\n",
      "Epoch 420/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0024\n",
      "Epoch 421/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0027\n",
      "Epoch 422/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0029\n",
      "Epoch 423/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0026\n",
      "Epoch 424/1000\n",
      "282/282 [==============================] - 0s 342us/sample - loss: 0.0025\n",
      "Epoch 425/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0027\n",
      "Epoch 426/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0024\n",
      "Epoch 427/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0024\n",
      "Epoch 428/1000\n",
      "282/282 [==============================] - 0s 314us/sample - loss: 0.0024\n",
      "Epoch 429/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0024\n",
      "Epoch 430/1000\n",
      "282/282 [==============================] - 0s 357us/sample - loss: 0.0024\n",
      "Epoch 431/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0024\n",
      "Epoch 432/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0024\n",
      "Epoch 433/1000\n",
      "282/282 [==============================] - 0s 334us/sample - loss: 0.0024\n",
      "Epoch 434/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0024\n",
      "Epoch 435/1000\n",
      "282/282 [==============================] - 0s 357us/sample - loss: 0.0024\n",
      "Epoch 436/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0024\n",
      "Epoch 437/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0024\n",
      "Epoch 438/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0024\n",
      "Epoch 439/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0023\n",
      "Epoch 440/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0023\n",
      "Epoch 441/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0024\n",
      "Epoch 442/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0024\n",
      "Epoch 443/1000\n",
      "282/282 [==============================] - 0s 317us/sample - loss: 0.0024\n",
      "Epoch 444/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0023\n",
      "Epoch 445/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0023\n",
      "Epoch 446/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0024\n",
      "Epoch 447/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0024\n",
      "Epoch 448/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0024\n",
      "Epoch 449/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0023\n",
      "Epoch 450/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0023\n",
      "Epoch 451/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0023\n",
      "Epoch 452/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0024\n",
      "Epoch 453/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0023\n",
      "Epoch 454/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0024\n",
      "Epoch 455/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0023\n",
      "Epoch 456/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0025\n",
      "Epoch 457/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0024\n",
      "Epoch 458/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0023\n",
      "Epoch 459/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0024\n",
      "Epoch 460/1000\n",
      "282/282 [==============================] - 0s 345us/sample - loss: 0.0023\n",
      "Epoch 461/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0023\n",
      "Epoch 462/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0024\n",
      "Epoch 463/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0024\n",
      "Epoch 464/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0025\n",
      "Epoch 465/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0025\n",
      "Epoch 466/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0026\n",
      "Epoch 467/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0024\n",
      "Epoch 468/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0024\n",
      "Epoch 469/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0024\n",
      "Epoch 470/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0023\n",
      "Epoch 471/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0023\n",
      "Epoch 472/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0023\n",
      "Epoch 473/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0026\n",
      "Epoch 474/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0023\n",
      "Epoch 475/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0025\n",
      "Epoch 476/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0024\n",
      "Epoch 477/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0023\n",
      "Epoch 478/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0023\n",
      "Epoch 479/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0023\n",
      "Epoch 480/1000\n",
      "282/282 [==============================] - 0s 360us/sample - loss: 0.0023\n",
      "Epoch 481/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0024\n",
      "Epoch 482/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0023\n",
      "Epoch 483/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0023\n",
      "Epoch 484/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0025\n",
      "Epoch 485/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0025\n",
      "Epoch 486/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0023\n",
      "Epoch 487/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0023\n",
      "Epoch 488/1000\n",
      "282/282 [==============================] - 0s 346us/sample - loss: 0.0023\n",
      "Epoch 489/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0023\n",
      "Epoch 490/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0024\n",
      "Epoch 491/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0024\n",
      "Epoch 492/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0024\n",
      "Epoch 493/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0023\n",
      "Epoch 494/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 495/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0024\n",
      "Epoch 496/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0025\n",
      "Epoch 497/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0026\n",
      "Epoch 498/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0024\n",
      "Epoch 499/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0023\n",
      "Epoch 500/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0022\n",
      "Epoch 501/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0023\n",
      "Epoch 502/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0023\n",
      "Epoch 503/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0023\n",
      "Epoch 504/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0023\n",
      "Epoch 505/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0022\n",
      "Epoch 506/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0022\n",
      "Epoch 507/1000\n",
      "282/282 [==============================] - 0s 390us/sample - loss: 0.0023\n",
      "Epoch 508/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0024\n",
      "Epoch 509/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0023\n",
      "Epoch 510/1000\n",
      "282/282 [==============================] - 0s 377us/sample - loss: 0.0026\n",
      "Epoch 511/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0029\n",
      "Epoch 512/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0027\n",
      "Epoch 513/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0023\n",
      "Epoch 514/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0022\n",
      "Epoch 515/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0022\n",
      "Epoch 516/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0023\n",
      "Epoch 517/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0025\n",
      "Epoch 518/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0023\n",
      "Epoch 519/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0023\n",
      "Epoch 520/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0023\n",
      "Epoch 521/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0023\n",
      "Epoch 522/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0023\n",
      "Epoch 523/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0025\n",
      "Epoch 524/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0025\n",
      "Epoch 525/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0023\n",
      "Epoch 526/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0027\n",
      "Epoch 527/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0024\n",
      "Epoch 528/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0024\n",
      "Epoch 529/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0022\n",
      "Epoch 530/1000\n",
      "282/282 [==============================] - 0s 335us/sample - loss: 0.0023\n",
      "Epoch 531/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0023\n",
      "Epoch 532/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0023\n",
      "Epoch 533/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0023\n",
      "Epoch 534/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0022\n",
      "Epoch 535/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 536/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0024\n",
      "Epoch 537/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0022\n",
      "Epoch 538/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0022\n",
      "Epoch 539/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0022\n",
      "Epoch 540/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0023\n",
      "Epoch 541/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0022\n",
      "Epoch 542/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 543/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0022\n",
      "Epoch 544/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 545/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0023\n",
      "Epoch 546/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0024\n",
      "Epoch 547/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0023\n",
      "Epoch 548/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0028\n",
      "Epoch 549/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0026\n",
      "Epoch 550/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0023\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0023\n",
      "Epoch 552/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0024\n",
      "Epoch 553/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0023\n",
      "Epoch 554/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0024\n",
      "Epoch 555/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0023\n",
      "Epoch 556/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0022\n",
      "Epoch 557/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0022\n",
      "Epoch 558/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0022\n",
      "Epoch 559/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0022\n",
      "Epoch 560/1000\n",
      "282/282 [==============================] - 0s 356us/sample - loss: 0.0022\n",
      "Epoch 561/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0022\n",
      "Epoch 562/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0022\n",
      "Epoch 563/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0022\n",
      "Epoch 564/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0023\n",
      "Epoch 565/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0024\n",
      "Epoch 566/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0025\n",
      "Epoch 567/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0024\n",
      "Epoch 568/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0024\n",
      "Epoch 569/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0024\n",
      "Epoch 570/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0023\n",
      "Epoch 571/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0022\n",
      "Epoch 572/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0022\n",
      "Epoch 573/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0023\n",
      "Epoch 574/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 575/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0021\n",
      "Epoch 576/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 577/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 578/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0022\n",
      "Epoch 579/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0023\n",
      "Epoch 580/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0022\n",
      "Epoch 581/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0022\n",
      "Epoch 582/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0023\n",
      "Epoch 583/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0022\n",
      "Epoch 584/1000\n",
      "282/282 [==============================] - 0s 281us/sample - loss: 0.0022\n",
      "Epoch 585/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0022\n",
      "Epoch 586/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0021\n",
      "Epoch 587/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0023\n",
      "Epoch 588/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0023\n",
      "Epoch 589/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 590/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0021\n",
      "Epoch 591/1000\n",
      "282/282 [==============================] - 0s 345us/sample - loss: 0.0021\n",
      "Epoch 592/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0022\n",
      "Epoch 593/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0022\n",
      "Epoch 594/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0022\n",
      "Epoch 595/1000\n",
      "282/282 [==============================] - 0s 323us/sample - loss: 0.0022\n",
      "Epoch 596/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 597/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0022\n",
      "Epoch 598/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0021\n",
      "Epoch 599/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 600/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0023\n",
      "Epoch 601/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0022\n",
      "Epoch 602/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0022\n",
      "Epoch 603/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0022\n",
      "Epoch 604/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0021\n",
      "Epoch 605/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 606/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0024\n",
      "Epoch 607/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0022\n",
      "Epoch 608/1000\n",
      "282/282 [==============================] - 0s 335us/sample - loss: 0.0022\n",
      "Epoch 609/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0023\n",
      "Epoch 610/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0025\n",
      "Epoch 611/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 612/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 613/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 614/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0024\n",
      "Epoch 615/1000\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.002 - 0s 341us/sample - loss: 0.0026\n",
      "Epoch 616/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0022\n",
      "Epoch 617/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0021\n",
      "Epoch 618/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0023\n",
      "Epoch 619/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0024\n",
      "Epoch 620/1000\n",
      "282/282 [==============================] - 0s 358us/sample - loss: 0.0023\n",
      "Epoch 621/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0023\n",
      "Epoch 622/1000\n",
      "282/282 [==============================] - 0s 333us/sample - loss: 0.0023\n",
      "Epoch 623/1000\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.002 - 0s 300us/sample - loss: 0.0021\n",
      "Epoch 624/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0021\n",
      "Epoch 625/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 626/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0022\n",
      "Epoch 627/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0023\n",
      "Epoch 628/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0022\n",
      "Epoch 629/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0021\n",
      "Epoch 630/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0021\n",
      "Epoch 631/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0022\n",
      "Epoch 632/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0022\n",
      "Epoch 633/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0021\n",
      "Epoch 634/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0021\n",
      "Epoch 635/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 636/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0021\n",
      "Epoch 637/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0021\n",
      "Epoch 638/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 639/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 640/1000\n",
      "282/282 [==============================] - 0s 321us/sample - loss: 0.0021\n",
      "Epoch 641/1000\n",
      "282/282 [==============================] - 0s 357us/sample - loss: 0.0022\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 643/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 644/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0022\n",
      "Epoch 645/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 646/1000\n",
      "282/282 [==============================] - 0s 310us/sample - loss: 0.0023\n",
      "Epoch 647/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0022\n",
      "Epoch 648/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0021\n",
      "Epoch 649/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0021\n",
      "Epoch 650/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0021\n",
      "Epoch 651/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0022\n",
      "Epoch 652/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0022\n",
      "Epoch 653/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0021\n",
      "Epoch 654/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0021\n",
      "Epoch 655/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 656/1000\n",
      "282/282 [==============================] - 0s 326us/sample - loss: 0.0025\n",
      "Epoch 657/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0022\n",
      "Epoch 658/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0022\n",
      "Epoch 659/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0023\n",
      "Epoch 660/1000\n",
      "282/282 [==============================] - 0s 333us/sample - loss: 0.0022\n",
      "Epoch 661/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0021\n",
      "Epoch 662/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0020\n",
      "Epoch 663/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 664/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0022\n",
      "Epoch 665/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 666/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0021\n",
      "Epoch 667/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 668/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0021\n",
      "Epoch 669/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 670/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0025\n",
      "Epoch 671/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0023\n",
      "Epoch 672/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0024\n",
      "Epoch 673/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0022\n",
      "Epoch 674/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 675/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0020\n",
      "Epoch 676/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0021\n",
      "Epoch 677/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0022\n",
      "Epoch 678/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0021\n",
      "Epoch 679/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0021\n",
      "Epoch 680/1000\n",
      "282/282 [==============================] - 0s 375us/sample - loss: 0.0020\n",
      "Epoch 681/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0021\n",
      "Epoch 682/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0022\n",
      "Epoch 683/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0021\n",
      "Epoch 684/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0022\n",
      "Epoch 685/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 686/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0021\n",
      "Epoch 687/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0021\n",
      "Epoch 688/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0021\n",
      "Epoch 689/1000\n",
      "282/282 [==============================] - 0s 326us/sample - loss: 0.0021\n",
      "Epoch 690/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0021\n",
      "Epoch 691/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0021\n",
      "Epoch 692/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 693/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0020\n",
      "Epoch 694/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0022\n",
      "Epoch 695/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0021\n",
      "Epoch 696/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0022\n",
      "Epoch 697/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0021\n",
      "Epoch 698/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0020\n",
      "Epoch 699/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 700/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0020\n",
      "Epoch 701/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0020\n",
      "Epoch 702/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 703/1000\n",
      "282/282 [==============================] - 0s 347us/sample - loss: 0.0020\n",
      "Epoch 704/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0020\n",
      "Epoch 705/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 706/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0021\n",
      "Epoch 707/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0021\n",
      "Epoch 708/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0021\n",
      "Epoch 709/1000\n",
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0021\n",
      "Epoch 710/1000\n",
      "282/282 [==============================] - 0s 310us/sample - loss: 0.0021\n",
      "Epoch 711/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0021\n",
      "Epoch 712/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 713/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0020\n",
      "Epoch 714/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0020\n",
      "Epoch 715/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 716/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 717/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0020\n",
      "Epoch 718/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0021\n",
      "Epoch 719/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0020\n",
      "Epoch 720/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0021\n",
      "Epoch 721/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0020\n",
      "Epoch 722/1000\n",
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0020\n",
      "Epoch 723/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 724/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0020\n",
      "Epoch 725/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0021\n",
      "Epoch 726/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 727/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0021\n",
      "Epoch 728/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 729/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0021\n",
      "Epoch 730/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0021\n",
      "Epoch 731/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0027\n",
      "Epoch 732/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0022\n",
      "Epoch 733/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0020\n",
      "Epoch 734/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 310us/sample - loss: 0.0020\n",
      "Epoch 735/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 736/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0020\n",
      "Epoch 737/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0020\n",
      "Epoch 738/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0020\n",
      "Epoch 739/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0020\n",
      "Epoch 740/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0020\n",
      "Epoch 741/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0020\n",
      "Epoch 742/1000\n",
      "282/282 [==============================] - 0s 252us/sample - loss: 0.0020\n",
      "Epoch 743/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0020\n",
      "Epoch 744/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0020\n",
      "Epoch 745/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0020\n",
      "Epoch 746/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 747/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 748/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0020\n",
      "Epoch 749/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0020\n",
      "Epoch 750/1000\n",
      "282/282 [==============================] - 0s 310us/sample - loss: 0.0020\n",
      "Epoch 751/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 752/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0020\n",
      "Epoch 753/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 754/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0020\n",
      "Epoch 755/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0020\n",
      "Epoch 756/1000\n",
      "282/282 [==============================] - 0s 354us/sample - loss: 0.0020\n",
      "Epoch 757/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0021\n",
      "Epoch 758/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0021\n",
      "Epoch 759/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0020\n",
      "Epoch 760/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 761/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0022\n",
      "Epoch 762/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0023\n",
      "Epoch 763/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0022\n",
      "Epoch 764/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0021\n",
      "Epoch 765/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0021\n",
      "Epoch 766/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0021\n",
      "Epoch 767/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0022\n",
      "Epoch 768/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0021\n",
      "Epoch 769/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 770/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0020\n",
      "Epoch 771/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0022\n",
      "Epoch 772/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0021\n",
      "Epoch 773/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0020\n",
      "Epoch 774/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0021\n",
      "Epoch 775/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0020\n",
      "Epoch 776/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 777/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0020\n",
      "Epoch 778/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 779/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0020\n",
      "Epoch 780/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 781/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0021\n",
      "Epoch 782/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0022\n",
      "Epoch 783/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0020\n",
      "Epoch 784/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0020\n",
      "Epoch 785/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0020\n",
      "Epoch 786/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0020\n",
      "Epoch 787/1000\n",
      "282/282 [==============================] - 0s 395us/sample - loss: 0.0021\n",
      "Epoch 788/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0020\n",
      "Epoch 789/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0020\n",
      "Epoch 790/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0023\n",
      "Epoch 791/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0023\n",
      "Epoch 792/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0020\n",
      "Epoch 793/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0025\n",
      "Epoch 794/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0024\n",
      "Epoch 795/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0021\n",
      "Epoch 796/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0021\n",
      "Epoch 797/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0019\n",
      "Epoch 798/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0020\n",
      "Epoch 799/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0020\n",
      "Epoch 800/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0019\n",
      "Epoch 801/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0019\n",
      "Epoch 802/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0021\n",
      "Epoch 803/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0020\n",
      "Epoch 804/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0020\n",
      "Epoch 805/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0020\n",
      "Epoch 806/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0019\n",
      "Epoch 807/1000\n",
      "282/282 [==============================] - 0s 317us/sample - loss: 0.0019\n",
      "Epoch 808/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 809/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0022\n",
      "Epoch 810/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0020\n",
      "Epoch 811/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0019\n",
      "Epoch 812/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0020\n",
      "Epoch 813/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 814/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0019\n",
      "Epoch 815/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0021\n",
      "Epoch 816/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0020\n",
      "Epoch 817/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0021\n",
      "Epoch 818/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0020\n",
      "Epoch 819/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0019\n",
      "Epoch 820/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0019\n",
      "Epoch 821/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0020\n",
      "Epoch 822/1000\n",
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0020\n",
      "Epoch 823/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0022\n",
      "Epoch 824/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0022\n",
      "Epoch 825/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0020\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0020\n",
      "Epoch 827/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0020\n",
      "Epoch 828/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 829/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0020\n",
      "Epoch 830/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0020\n",
      "Epoch 831/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0019\n",
      "Epoch 832/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0019\n",
      "Epoch 833/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0019\n",
      "Epoch 834/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0020\n",
      "Epoch 835/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0021\n",
      "Epoch 836/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0019\n",
      "Epoch 837/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0021\n",
      "Epoch 838/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0023\n",
      "Epoch 839/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0023\n",
      "Epoch 840/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 841/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0020\n",
      "Epoch 842/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0019\n",
      "Epoch 843/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0022\n",
      "Epoch 844/1000\n",
      "282/282 [==============================] - 0s 286us/sample - loss: 0.0025\n",
      "Epoch 845/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0024\n",
      "Epoch 846/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0021\n",
      "Epoch 847/1000\n",
      "282/282 [==============================] - 0s 335us/sample - loss: 0.0020\n",
      "Epoch 848/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0020\n",
      "Epoch 849/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0021\n",
      "Epoch 850/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0022\n",
      "Epoch 851/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0023\n",
      "Epoch 852/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0020\n",
      "Epoch 853/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0021\n",
      "Epoch 854/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0020\n",
      "Epoch 855/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 856/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0020\n",
      "Epoch 857/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 858/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0019\n",
      "Epoch 859/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0020\n",
      "Epoch 860/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0020\n",
      "Epoch 861/1000\n",
      "282/282 [==============================] - 0s 343us/sample - loss: 0.0020\n",
      "Epoch 862/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0020\n",
      "Epoch 863/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0020\n",
      "Epoch 864/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0019\n",
      "Epoch 865/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0019\n",
      "Epoch 866/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0019\n",
      "Epoch 867/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0020\n",
      "Epoch 868/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0020\n",
      "Epoch 869/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0020\n",
      "Epoch 870/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 871/1000\n",
      "282/282 [==============================] - 0s 334us/sample - loss: 0.0019\n",
      "Epoch 872/1000\n",
      "282/282 [==============================] - 0s 341us/sample - loss: 0.0019\n",
      "Epoch 873/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0019\n",
      "Epoch 874/1000\n",
      "282/282 [==============================] - 0s 397us/sample - loss: 0.0021\n",
      "Epoch 875/1000\n",
      "282/282 [==============================] - 0s 328us/sample - loss: 0.0021\n",
      "Epoch 876/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0020\n",
      "Epoch 877/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0019\n",
      "Epoch 878/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0019\n",
      "Epoch 879/1000\n",
      "282/282 [==============================] - 0s 364us/sample - loss: 0.0019\n",
      "Epoch 880/1000\n",
      "282/282 [==============================] - 0s 344us/sample - loss: 0.0019\n",
      "Epoch 881/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0022\n",
      "Epoch 882/1000\n",
      "282/282 [==============================] - 0s 314us/sample - loss: 0.0021\n",
      "Epoch 883/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0019\n",
      "Epoch 884/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0020\n",
      "Epoch 885/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0020\n",
      "Epoch 886/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0019\n",
      "Epoch 887/1000\n",
      "282/282 [==============================] - 0s 333us/sample - loss: 0.0020\n",
      "Epoch 888/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0019\n",
      "Epoch 889/1000\n",
      "282/282 [==============================] - 0s 467us/sample - loss: 0.0021\n",
      "Epoch 890/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0025\n",
      "Epoch 891/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0023\n",
      "Epoch 892/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0023\n",
      "Epoch 893/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0020\n",
      "Epoch 894/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 895/1000\n",
      "282/282 [==============================] - 0s 336us/sample - loss: 0.0019\n",
      "Epoch 896/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0020\n",
      "Epoch 897/1000\n",
      "282/282 [==============================] - 0s 339us/sample - loss: 0.0020\n",
      "Epoch 898/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0019\n",
      "Epoch 899/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0019\n",
      "Epoch 900/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0021\n",
      "Epoch 901/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0019\n",
      "Epoch 902/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0019\n",
      "Epoch 903/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0019\n",
      "Epoch 904/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0019\n",
      "Epoch 905/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0019\n",
      "Epoch 906/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0019\n",
      "Epoch 907/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0019\n",
      "Epoch 908/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0019\n",
      "Epoch 909/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0019\n",
      "Epoch 910/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0020\n",
      "Epoch 911/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0019\n",
      "Epoch 912/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0019\n",
      "Epoch 913/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0019\n",
      "Epoch 914/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0020\n",
      "Epoch 915/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0019\n",
      "Epoch 916/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0020\n",
      "Epoch 917/1000\n",
      "282/282 [==============================] - 0s 325us/sample - loss: 0.0019\n",
      "Epoch 918/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0019\n",
      "Epoch 919/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0019\n",
      "Epoch 920/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0019\n",
      "Epoch 921/1000\n",
      "282/282 [==============================] - 0s 277us/sample - loss: 0.0019\n",
      "Epoch 922/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0019\n",
      "Epoch 923/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0019\n",
      "Epoch 924/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0019\n",
      "Epoch 925/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0019\n",
      "Epoch 926/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0021\n",
      "Epoch 927/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0020\n",
      "Epoch 928/1000\n",
      "282/282 [==============================] - 0s 303us/sample - loss: 0.0020\n",
      "Epoch 929/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0023\n",
      "Epoch 930/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0022\n",
      "Epoch 931/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 932/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0019\n",
      "Epoch 933/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 934/1000\n",
      "282/282 [==============================] - 0s 322us/sample - loss: 0.0020\n",
      "Epoch 935/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0019\n",
      "Epoch 936/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0018\n",
      "Epoch 937/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0019\n",
      "Epoch 938/1000\n",
      "282/282 [==============================] - 0s 293us/sample - loss: 0.0019\n",
      "Epoch 939/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0019\n",
      "Epoch 940/1000\n",
      "282/282 [==============================] - 0s 317us/sample - loss: 0.0019\n",
      "Epoch 941/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0019\n",
      "Epoch 942/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0020\n",
      "Epoch 943/1000\n",
      "282/282 [==============================] - 0s 326us/sample - loss: 0.0019\n",
      "Epoch 944/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0019\n",
      "Epoch 945/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0019\n",
      "Epoch 946/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0020\n",
      "Epoch 947/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0021\n",
      "Epoch 948/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0020\n",
      "Epoch 949/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0022\n",
      "Epoch 950/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0023\n",
      "Epoch 951/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0020\n",
      "Epoch 952/1000\n",
      "282/282 [==============================] - 0s 300us/sample - loss: 0.0020\n",
      "Epoch 953/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0019\n",
      "Epoch 954/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0019\n",
      "Epoch 955/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0020\n",
      "Epoch 956/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0020\n",
      "Epoch 957/1000\n",
      "282/282 [==============================] - 0s 307us/sample - loss: 0.0019\n",
      "Epoch 958/1000\n",
      "282/282 [==============================] - 0s 311us/sample - loss: 0.0019\n",
      "Epoch 959/1000\n",
      "282/282 [==============================] - 0s 309us/sample - loss: 0.0019\n",
      "Epoch 960/1000\n",
      "282/282 [==============================] - 0s 252us/sample - loss: 0.0019\n",
      "Epoch 961/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0019\n",
      "Epoch 962/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0019\n",
      "Epoch 963/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0022\n",
      "Epoch 964/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0020\n",
      "Epoch 965/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0021\n",
      "Epoch 966/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0019\n",
      "Epoch 967/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0019\n",
      "Epoch 968/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0019\n",
      "Epoch 969/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0018\n",
      "Epoch 970/1000\n",
      "282/282 [==============================] - 0s 292us/sample - loss: 0.0019\n",
      "Epoch 971/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0019\n",
      "Epoch 972/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0019\n",
      "Epoch 973/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 974/1000\n",
      "282/282 [==============================] - 0s 304us/sample - loss: 0.0021\n",
      "Epoch 975/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0019\n",
      "Epoch 976/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0020\n",
      "Epoch 977/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0018\n",
      "Epoch 978/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0020\n",
      "Epoch 979/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0020\n",
      "Epoch 980/1000\n",
      "282/282 [==============================] - 0s 360us/sample - loss: 0.0019\n",
      "Epoch 981/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0021\n",
      "Epoch 982/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0021\n",
      "Epoch 983/1000\n",
      "282/282 [==============================] - 0s 305us/sample - loss: 0.0022\n",
      "Epoch 984/1000\n",
      "282/282 [==============================] - 0s 302us/sample - loss: 0.0020\n",
      "Epoch 985/1000\n",
      "282/282 [==============================] - 0s 350us/sample - loss: 0.0019\n",
      "Epoch 986/1000\n",
      "282/282 [==============================] - 0s 356us/sample - loss: 0.0020\n",
      "Epoch 987/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0019\n",
      "Epoch 988/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0018\n",
      "Epoch 989/1000\n",
      "282/282 [==============================] - 0s 338us/sample - loss: 0.0018\n",
      "Epoch 990/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0019\n",
      "Epoch 991/1000\n",
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0019\n",
      "Epoch 992/1000\n",
      "282/282 [==============================] - 0s 398us/sample - loss: 0.0020\n",
      "Epoch 993/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0022\n",
      "Epoch 994/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0019\n",
      "Epoch 995/1000\n",
      "282/282 [==============================] - 0s 306us/sample - loss: 0.0019\n",
      "Epoch 996/1000\n",
      "282/282 [==============================] - 0s 320us/sample - loss: 0.0018\n",
      "Epoch 997/1000\n",
      "282/282 [==============================] - 0s 312us/sample - loss: 0.0019\n",
      "Epoch 998/1000\n",
      "282/282 [==============================] - 0s 337us/sample - loss: 0.0018\n",
      "Epoch 999/1000\n",
      "282/282 [==============================] - 0s 331us/sample - loss: 0.0019\n",
      "Epoch 1000/1000\n",
      "282/282 [==============================] - 0s 318us/sample - loss: 0.0019\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 2, 1, 3, 12)       2736      \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 2, 1, 3, 12)       4656      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 73        \n",
      "=================================================================\n",
      "Total params: 7,465\n",
      "Trainable params: 7,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "MAE= [1.8140299]\n",
      "RMSE =  2.4093990774967797\n",
      "NMSE =  [0.00395885]\n",
      "MAPE= [0.00861498]\n",
      "IA= [0.98157495]\n",
      "U1= 0.005671148850519765\n",
      "U2= 0.47339349615617426\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 91 seconds\n"
     ]
    }
   ],
   "source": [
    "#ConvLSTM-SED   multivariable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import ConvLSTM2D\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#matplotlib inline\n",
    "import time\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "#dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/PD-TVFEMD-IMF1.csv', usecols=[6], engine='python')\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "#print(dataframe)\n",
    "print(\"数据集的长度：\",len(dataframe))\n",
    "dataset = dataframe.values\n",
    "# 将整型变为float\n",
    "dataset = dataset.astype('float32')\n",
    "#print(dataset)\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "\n",
    "#print(X_scaler)\n",
    "#print(Y_scaler)\n",
    "#print(Y)\n",
    "\n",
    "\n",
    "# 将数据拆分成训练和测试，8/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size,:], X_scaler[train_size:len(dataset),:]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX)\n",
    "#print(trainY)\n",
    "#print(testX)\n",
    "#print(testY)\n",
    "\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_trainX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_trainY(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i + timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "def create_testX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[(i):(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "\n",
    "\n",
    "#----------forecasting-----------\n",
    "\n",
    "pres=[]\n",
    "trainX = create_trainX(trainX, timestep)\n",
    "trainY = create_trainY(trainY, timestep)\n",
    "testX = create_testX(testX, timestep) \n",
    "testY = testY[timestep:len(testY)]\n",
    "print(\"转为监督学习，训练集数据长度：\", len(trainX))\n",
    "#print(trainX,trainY)\n",
    "print(\"转为监督学习，测试集数据长度：\",len(testX))\n",
    "#print(testX, testY )\n",
    "\n",
    "\n",
    "# 数据重构为5D [samples, timesteps, rows, columns, features]\n",
    "trainX_input5D = np.reshape(trainX, (trainX.shape[0], 2,1,timestep//2, dim))\n",
    "testX_input5D = np.reshape(testX, (testX.shape[0],2,1,timestep//2, dim))\n",
    "#trainX_input5D = np.reshape(trainX, (trainX.shape[0], timestep,1,1, dim))\n",
    "#testX_input5D = np.reshape(testX, (testX.shape[0],timestep,1,1, dim))\n",
    "print('构造得到模型的输入数据(训练数据已有标签trainY): ',trainX_input5D.shape,testX_input5D.shape)\n",
    "\n",
    "\n",
    "# create and fit the convlstm network\n",
    "if __name__ == '__main__':\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=12, kernel_size=(2,2), activation='relu', \n",
    "                         input_shape=(2,1,timestep//2, dim),\n",
    "#                         input_shape=(timestep,1,1, dim),\n",
    "                         padding='same', return_sequences=True))\n",
    "    model.add(ConvLSTM2D(filters=12, kernel_size=(2,2), activation='relu',\n",
    "                         padding='same', return_sequences=True))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(trainX_input5D, trainY, epochs=1000)\n",
    "\n",
    "    # 打印模型\n",
    "    model.summary()\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(trainX_input5D)\n",
    "    testPredict = model.predict(testX_input5D)\n",
    "\n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/convlstmbdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/convlstmbdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/convlstmoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/convlstmEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#ConvLSTM-SED   multivariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d71cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CNN-LSTM-SED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#matplotlib inline\n",
    "import time\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "#print(dataframe)\n",
    "print(\"数据集的长度：\",len(dataframe))\n",
    "dataset = dataframe.values\n",
    "# 将整型变为float\n",
    "dataset = dataset.astype('float32')\n",
    "#print(dataset)\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "\n",
    "\n",
    "# 将数据拆分成训练和测试，7/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size,:], X_scaler[train_size:len(dataset),:]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX)\n",
    "#print(trainY)\n",
    "#print(testX)\n",
    "#print(testY)\n",
    "\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_trainX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_trainY(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i + timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "def create_testX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[(i):(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "\n",
    "\n",
    "#----------forecasting-----------\n",
    "pres=[]\n",
    "trainX = create_trainX(trainX, timestep)\n",
    "trainY = create_trainY(trainY, timestep)\n",
    "testX = create_testX(testX, timestep) \n",
    "testY = testY[timestep:len(testY)]\n",
    "print(\"转为监督学习，训练集数据长度：\", len(trainX))\n",
    "#print(trainX,trainY)\n",
    "print(\"转为监督学习，测试集数据长度：\",len(testX))\n",
    "#print(testX, testY )\n",
    "\n",
    "\n",
    "# 数据重构为4D [samples, subsequences, timesteps, features]\n",
    "trainX_input4D = np.reshape(trainX, (trainX.shape[0],1,timestep,dim))\n",
    "testX_input4D = np.reshape(testX, (testX.shape[0],1,timestep,dim))\n",
    "print('构造得到模型的输入数据(训练数据已有标签trainY): ',trainX_input4D.shape,testX_input4D.shape)\n",
    "\n",
    "\n",
    "# create and fit the convlstm network\n",
    "if __name__ == '__main__':\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=36, kernel_size=3, activation='relu', input_shape=(None,1, testX.shape[1]))))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(60,activation='relu',return_sequences=True))\n",
    "    model.add(LSTM(12,activation='relu',return_sequences=True))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(trainX_input4D, trainY, epochs=1000)\n",
    "    \n",
    "\n",
    "\n",
    "    # 打印模型\n",
    "    model.summary()\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(trainX_input4D)\n",
    "    testPredict = model.predict(testX_input4D)\n",
    "\n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnbdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnbdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#CNN-LSTM-SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2121a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CNN-SED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#matplotlib inline\n",
    "import time\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "#print(dataframe)\n",
    "print(\"数据集的长度：\",len(dataframe))\n",
    "dataset = dataframe.values\n",
    "# 将整型变为float\n",
    "dataset = dataset.astype('float32')\n",
    "#print(dataset)\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "\n",
    "\n",
    "# 将数据拆分成训练和测试，7/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size,:], X_scaler[train_size:len(dataset),:]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX)\n",
    "#print(trainY)\n",
    "#print(testX)\n",
    "#print(testY)\n",
    "\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_trainX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_trainY(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i + timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "def create_testX(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[(i):(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "\n",
    "\n",
    "#----------forecasting-----------\n",
    "pres=[]\n",
    "trainX = create_trainX(trainX, timestep)\n",
    "trainY = create_trainY(trainY, timestep)\n",
    "testX = create_testX(testX, timestep) \n",
    "testY = testY[timestep:len(testY)]\n",
    "print(\"转为监督学习，训练集数据长度：\", len(trainX))\n",
    "#print(trainX,trainY)\n",
    "print(\"转为监督学习，测试集数据长度：\",len(testX))\n",
    "#print(testX, testY )\n",
    "\n",
    "\n",
    "# 数据重构为4D [samples, subsequences, timesteps, features]\n",
    "trainX_input4D = np.reshape(trainX, (trainX.shape[0],1,timestep,dim))\n",
    "testX_input4D = np.reshape(testX, (testX.shape[0],1,timestep,dim))\n",
    "print('构造得到模型的输入数据(训练数据已有标签trainY): ',trainX_input4D.shape,testX_input4D.shape)\n",
    "\n",
    "\n",
    "# create and fit the convlstm network\n",
    "if __name__ == '__main__':\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=42, kernel_size=3, activation='relu', input_shape=(None,1, testX.shape[1]))))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=1)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    #model.add(LSTM(4,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(trainX_input4D, trainY, epochs=1000)\n",
    "    \n",
    "\n",
    "\n",
    "    # 打印模型\n",
    "    model.summary()\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(trainX_input4D)\n",
    "    testPredict = model.predict(testX_input4D)\n",
    "\n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnbdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnbdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/cnnEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#CNN-SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a159f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GRU_SED\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import merge\n",
    "from tensorflow.python.keras.layers.merge import Multiply\n",
    "from tensorflow.python.keras.layers.core import *\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.layers import Input,Dense,Reshape,Dropout, Embedding, LSTM, Bidirectional,Permute\n",
    "from tensorflow.python.keras.layers import RepeatVector, TimeDistributed\n",
    "from tensorflow.python.keras.layers.recurrent import GRU\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import concat, read_csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as skm\n",
    "import math\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "np.random.seed(6)\n",
    "#1. load dataset\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "data = dataset.reshape(-1,6)\n",
    "\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "print(X_scaler.shape)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "print(Y_scaler.shape)\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_X(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_Y(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i+timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "#-------------------------------------------#\n",
    "#  建立注意力模型\n",
    "#-------------------------------------------#\n",
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    # Documentation is available online on Github at the address below.\n",
    "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
    "#    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "#        if print_shape_only:\n",
    "#            print(layer_activations.shape)\n",
    "#        else:\n",
    "#            print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)#(batch_size, time_steps, input_dim)\n",
    "    output_attention_mul = Multiply()([inputs, a_probs])#(batch_size, time_steps, input_dim)\n",
    "    return output_attention_mul\n",
    "\n",
    "\n",
    "def get_gru_model():\n",
    "    K.clear_session() #清除之前的模型，省得压满内存\n",
    "    inputs = Input(shape=(timestep, dim,))\n",
    "    gru_units1 = 24\n",
    "    gru_units2 = 12\n",
    "    # (batch_size, time_steps, INPUT_DIM) -> (batch_size, input_dim, lstm_units)\n",
    "    gur_out1 = GRU(gru_units1,return_sequences=True)(inputs)\n",
    "    gur_out2 = GRU(gru_units2,return_sequences=True)(gur_out1)\n",
    "    # (batch_size, input_dim, lstm_units) -> (batch_size, input_dim*lstm_units)\n",
    "    dropout_out = Dropout(0.5)(gur_out2)\n",
    "    gur_out = Flatten()(dropout_out)\n",
    "    output = Dense(1, activation='sigmoid')(gur_out)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#预测\n",
    "pres=[]\n",
    "# 将数据拆分成训练和测试，7/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size,:], X_scaler[train_size:len(dataset),:]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX,trainX.shape)\n",
    "#print(trainY,trainY.shape)\n",
    "#print(testX,testX.shape)\n",
    "#print(testY,testY.shape)\n",
    "\n",
    "train_X=create_X(trainX,timestep)#(246,6,6)\n",
    "#print(train_X,train_X.shape)\n",
    "train_Y=create_Y(trainY,timestep)#(246,)\n",
    "#print(train_Y,train_Y.shape)\n",
    "test_X=create_X(testX,timestep)#(66,6,6)\n",
    "#print(test_X,test_X.shape)\n",
    "test_Y=create_Y(testY,timestep)#(66,)\n",
    "#print(test_Y,test_Y.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    model = get_gru_model()\n",
    "    optimizer = Adam(0.01)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=1000, batch_size=64)\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(train_X)\n",
    "    testPredict = model.predict(test_X)\n",
    "    \n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/grubdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/grubdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/gruoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/gruEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#GRU_SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160cdff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LSTM-SED\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import merge\n",
    "from tensorflow.python.keras.layers.merge import Multiply\n",
    "from tensorflow.python.keras.layers.core import *\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.layers import Input,Dense,Reshape,Dropout, Embedding, LSTM, Bidirectional,Permute\n",
    "from tensorflow.python.keras.layers import RepeatVector, TimeDistributed\n",
    "from tensorflow.python.keras.layers.recurrent import GRU\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import concat, read_csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as skm\n",
    "import math\n",
    "from math import sqrt\n",
    "np.random.seed(6)\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#1. load dataset\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "data = dataset.reshape(-1,6)\n",
    "\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "print(X_scaler.shape)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "print(Y_scaler.shape)\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_X(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_Y(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i+timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "\n",
    "\n",
    "def get_lstm_model():\n",
    "    K.clear_session() #清除之前的模型，省得压满内存\n",
    "    inputs = Input(shape=(timestep, dim,))\n",
    "    lstm_units1 = 12\n",
    "    lstm_units2 = 36\n",
    "    lstm_out1 = LSTM(lstm_units1, return_sequences=True)(inputs)\n",
    "    lstm_out2 = LSTM(lstm_units2, return_sequences=True)(lstm_out1)\n",
    "    dropout_out = Dropout(0.5)(lstm_out2)\n",
    "    lstm_out = Flatten()(dropout_out)\n",
    "    output = Dense(1, activation='relu')(lstm_out)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#预测\n",
    "pres=[]\n",
    "# 将数据拆分成训练和测试，7/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size], X_scaler[train_size:len(dataset)]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX,trainX.shape)\n",
    "#print(trainY,trainY.shape)\n",
    "#print(testX,testX.shape)\n",
    "#print(testY,testY.shape)\n",
    "\n",
    "train_X=create_X(trainX,timestep)#(246,6)\n",
    "#print(train_X,train_X.shape)\n",
    "train_Y=create_Y(trainY,timestep)#(246,)\n",
    "#print(train_Y,train_Y.shape)\n",
    "test_X=create_X(testX,timestep)#(66,6,6)\n",
    "#print(test_X,test_X.shape)\n",
    "test_Y=create_Y(testY,timestep)#(66,)\n",
    "#print(test_Y,test_Y.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(6)\n",
    "        \n",
    "    model = get_lstm_model()\n",
    "    optimizer = Adam(0.01)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=1000, batch_size=64)\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(train_X)\n",
    "    testPredict = model.predict(test_X)\n",
    "    \n",
    "    \n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmbdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmbdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#LSTM-SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e01b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 2)\n",
      "(324,)\n",
      "原始训练集的长度： 288\n",
      "原始测试集的长度： 36\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 2)]            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 6, 12)             432       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 36)             7056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 36)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 217       \n",
      "=================================================================\n",
      "Total params: 7,705\n",
      "Trainable params: 7,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 282 samples\n",
      "Epoch 1/1000\n",
      "282/282 [==============================] - 6s 20ms/sample - loss: 0.0999\n",
      "Epoch 2/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0419\n",
      "Epoch 3/1000\n",
      "282/282 [==============================] - 0s 191us/sample - loss: 0.0347\n",
      "Epoch 4/1000\n",
      "282/282 [==============================] - 0s 217us/sample - loss: 0.0363\n",
      "Epoch 5/1000\n",
      "282/282 [==============================] - 0s 211us/sample - loss: 0.0337\n",
      "Epoch 6/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0314\n",
      "Epoch 7/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0307\n",
      "Epoch 8/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0268\n",
      "Epoch 9/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0275\n",
      "Epoch 10/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0257\n",
      "Epoch 11/1000\n",
      "282/282 [==============================] - 0s 215us/sample - loss: 0.0221\n",
      "Epoch 12/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0199\n",
      "Epoch 13/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0179\n",
      "Epoch 14/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0248\n",
      "Epoch 15/1000\n",
      "282/282 [==============================] - 0s 209us/sample - loss: 0.0248\n",
      "Epoch 16/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0198\n",
      "Epoch 17/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0201\n",
      "Epoch 18/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0185\n",
      "Epoch 19/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0191\n",
      "Epoch 20/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0164\n",
      "Epoch 21/1000\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.0172\n",
      "Epoch 22/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0161\n",
      "Epoch 23/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0156\n",
      "Epoch 24/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0149\n",
      "Epoch 25/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0181\n",
      "Epoch 26/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0162\n",
      "Epoch 27/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0159\n",
      "Epoch 28/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0148\n",
      "Epoch 29/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0150\n",
      "Epoch 30/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0131\n",
      "Epoch 31/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0141\n",
      "Epoch 32/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0123\n",
      "Epoch 33/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0153\n",
      "Epoch 34/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0119\n",
      "Epoch 35/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0136\n",
      "Epoch 36/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0125\n",
      "Epoch 37/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0140\n",
      "Epoch 38/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0146\n",
      "Epoch 39/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0126\n",
      "Epoch 40/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0139\n",
      "Epoch 41/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0105\n",
      "Epoch 42/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0110\n",
      "Epoch 43/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0124\n",
      "Epoch 44/1000\n",
      "282/282 [==============================] - 0s 218us/sample - loss: 0.0107\n",
      "Epoch 45/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0106\n",
      "Epoch 46/1000\n",
      "282/282 [==============================] - 0s 261us/sample - loss: 0.0106\n",
      "Epoch 47/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0119\n",
      "Epoch 48/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0100\n",
      "Epoch 49/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0107\n",
      "Epoch 50/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0101\n",
      "Epoch 51/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0101\n",
      "Epoch 52/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0101\n",
      "Epoch 53/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0112\n",
      "Epoch 54/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0109\n",
      "Epoch 55/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0108\n",
      "Epoch 56/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0094\n",
      "Epoch 57/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0100\n",
      "Epoch 58/1000\n",
      "282/282 [==============================] - 0s 218us/sample - loss: 0.0134\n",
      "Epoch 59/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0117\n",
      "Epoch 60/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0090\n",
      "Epoch 61/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0085\n",
      "Epoch 62/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0085\n",
      "Epoch 63/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0093\n",
      "Epoch 64/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0085\n",
      "Epoch 65/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0085\n",
      "Epoch 66/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0081\n",
      "Epoch 67/1000\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.0077\n",
      "Epoch 68/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0076\n",
      "Epoch 69/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0076\n",
      "Epoch 70/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0078\n",
      "Epoch 71/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0079\n",
      "Epoch 72/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0070\n",
      "Epoch 73/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0069\n",
      "Epoch 74/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0076\n",
      "Epoch 75/1000\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.0077\n",
      "Epoch 76/1000\n",
      "282/282 [==============================] - 0s 204us/sample - loss: 0.0069\n",
      "Epoch 77/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0068\n",
      "Epoch 78/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0064\n",
      "Epoch 79/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0066\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0061\n",
      "Epoch 81/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0065\n",
      "Epoch 82/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0060\n",
      "Epoch 83/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0065\n",
      "Epoch 84/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0059\n",
      "Epoch 85/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0054\n",
      "Epoch 86/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0054\n",
      "Epoch 87/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0053\n",
      "Epoch 88/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0046\n",
      "Epoch 89/1000\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.0051\n",
      "Epoch 90/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0056\n",
      "Epoch 91/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0050\n",
      "Epoch 92/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0058\n",
      "Epoch 93/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0053\n",
      "Epoch 94/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0055\n",
      "Epoch 95/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0052\n",
      "Epoch 96/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0046\n",
      "Epoch 97/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0052\n",
      "Epoch 98/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0043\n",
      "Epoch 99/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0044\n",
      "Epoch 100/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0041\n",
      "Epoch 101/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0046\n",
      "Epoch 102/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0049\n",
      "Epoch 103/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0043\n",
      "Epoch 104/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0044\n",
      "Epoch 105/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0042\n",
      "Epoch 106/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0044\n",
      "Epoch 107/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0041\n",
      "Epoch 108/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0041\n",
      "Epoch 109/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0049\n",
      "Epoch 110/1000\n",
      "282/282 [==============================] - 0s 211us/sample - loss: 0.0047\n",
      "Epoch 111/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0043\n",
      "Epoch 112/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0044\n",
      "Epoch 113/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0039\n",
      "Epoch 114/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0042\n",
      "Epoch 115/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0043\n",
      "Epoch 116/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0041\n",
      "Epoch 117/1000\n",
      "282/282 [==============================] - 0s 205us/sample - loss: 0.0044\n",
      "Epoch 118/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0041\n",
      "Epoch 119/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0042\n",
      "Epoch 120/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0041\n",
      "Epoch 121/1000\n",
      "282/282 [==============================] - 0s 204us/sample - loss: 0.0041\n",
      "Epoch 122/1000\n",
      "282/282 [==============================] - 0s 220us/sample - loss: 0.0053\n",
      "Epoch 123/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0050\n",
      "Epoch 124/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0044\n",
      "Epoch 125/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0043\n",
      "Epoch 126/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0045\n",
      "Epoch 127/1000\n",
      "282/282 [==============================] - 0s 211us/sample - loss: 0.0041\n",
      "Epoch 128/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0042\n",
      "Epoch 129/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0037\n",
      "Epoch 130/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0038\n",
      "Epoch 131/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0045\n",
      "Epoch 132/1000\n",
      "282/282 [==============================] - 0s 209us/sample - loss: 0.0038\n",
      "Epoch 133/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0039\n",
      "Epoch 134/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0041\n",
      "Epoch 135/1000\n",
      "282/282 [==============================] - 0s 218us/sample - loss: 0.0043\n",
      "Epoch 136/1000\n",
      "282/282 [==============================] - 0s 208us/sample - loss: 0.0039\n",
      "Epoch 137/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0040\n",
      "Epoch 138/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0039\n",
      "Epoch 139/1000\n",
      "282/282 [==============================] - 0s 214us/sample - loss: 0.0038\n",
      "Epoch 140/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0036\n",
      "Epoch 141/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0039\n",
      "Epoch 142/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0042\n",
      "Epoch 143/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0038\n",
      "Epoch 144/1000\n",
      "282/282 [==============================] - 0s 212us/sample - loss: 0.0040\n",
      "Epoch 145/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0038\n",
      "Epoch 146/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0036\n",
      "Epoch 147/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0036\n",
      "Epoch 148/1000\n",
      "282/282 [==============================] - 0s 211us/sample - loss: 0.0034\n",
      "Epoch 149/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0035\n",
      "Epoch 150/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0037\n",
      "Epoch 151/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0041\n",
      "Epoch 152/1000\n",
      "282/282 [==============================] - 0s 263us/sample - loss: 0.0039\n",
      "Epoch 153/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0038\n",
      "Epoch 154/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0035\n",
      "Epoch 155/1000\n",
      "282/282 [==============================] - 0s 297us/sample - loss: 0.0033\n",
      "Epoch 156/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0034\n",
      "Epoch 157/1000\n",
      "282/282 [==============================] - 0s 308us/sample - loss: 0.0034\n",
      "Epoch 158/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0033\n",
      "Epoch 159/1000\n",
      "282/282 [==============================] - 0s 327us/sample - loss: 0.0039\n",
      "Epoch 160/1000\n",
      "282/282 [==============================] - 0s 328us/sample - loss: 0.0034\n",
      "Epoch 161/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0037\n",
      "Epoch 162/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0037\n",
      "Epoch 163/1000\n",
      "282/282 [==============================] - 0s 376us/sample - loss: 0.0036\n",
      "Epoch 164/1000\n",
      "282/282 [==============================] - 0s 313us/sample - loss: 0.0035\n",
      "Epoch 165/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0036\n",
      "Epoch 166/1000\n",
      "282/282 [==============================] - 0s 321us/sample - loss: 0.0042\n",
      "Epoch 167/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0033\n",
      "Epoch 168/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0033\n",
      "Epoch 169/1000\n",
      "282/282 [==============================] - 0s 301us/sample - loss: 0.0035\n",
      "Epoch 170/1000\n",
      "282/282 [==============================] - 0s 319us/sample - loss: 0.0033\n",
      "Epoch 171/1000\n",
      "282/282 [==============================] - 0s 299us/sample - loss: 0.0033\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 316us/sample - loss: 0.0042\n",
      "Epoch 173/1000\n",
      "282/282 [==============================] - 0s 337us/sample - loss: 0.0037\n",
      "Epoch 174/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0034\n",
      "Epoch 175/1000\n",
      "282/282 [==============================] - 0s 356us/sample - loss: 0.0036s - loss: 0.003\n",
      "Epoch 176/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0040\n",
      "Epoch 177/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0034\n",
      "Epoch 178/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0032\n",
      "Epoch 179/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0036\n",
      "Epoch 180/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0033\n",
      "Epoch 181/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0037\n",
      "Epoch 182/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0036\n",
      "Epoch 183/1000\n",
      "282/282 [==============================] - 0s 291us/sample - loss: 0.0034\n",
      "Epoch 184/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0038\n",
      "Epoch 185/1000\n",
      "282/282 [==============================] - 0s 298us/sample - loss: 0.0037\n",
      "Epoch 186/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0038\n",
      "Epoch 187/1000\n",
      "282/282 [==============================] - 0s 295us/sample - loss: 0.0033\n",
      "Epoch 188/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0031\n",
      "Epoch 189/1000\n",
      "282/282 [==============================] - 0s 329us/sample - loss: 0.0033\n",
      "Epoch 190/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0035\n",
      "Epoch 191/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0033\n",
      "Epoch 192/1000\n",
      "282/282 [==============================] - 0s 443us/sample - loss: 0.0033\n",
      "Epoch 193/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0031\n",
      "Epoch 194/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0033\n",
      "Epoch 195/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0034\n",
      "Epoch 196/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0038\n",
      "Epoch 197/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0033\n",
      "Epoch 198/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0036\n",
      "Epoch 199/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0032\n",
      "Epoch 200/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0032\n",
      "Epoch 201/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0034\n",
      "Epoch 202/1000\n",
      "282/282 [==============================] - 0s 273us/sample - loss: 0.0034\n",
      "Epoch 203/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0033\n",
      "Epoch 204/1000\n",
      "282/282 [==============================] - 0s 267us/sample - loss: 0.0034\n",
      "Epoch 205/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0030\n",
      "Epoch 206/1000\n",
      "282/282 [==============================] - 0s 263us/sample - loss: 0.0031\n",
      "Epoch 207/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0033\n",
      "Epoch 208/1000\n",
      "282/282 [==============================] - 0s 270us/sample - loss: 0.0032\n",
      "Epoch 209/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0033\n",
      "Epoch 210/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0033\n",
      "Epoch 211/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0035\n",
      "Epoch 212/1000\n",
      "282/282 [==============================] - 0s 285us/sample - loss: 0.0032\n",
      "Epoch 213/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0032\n",
      "Epoch 214/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0035\n",
      "Epoch 215/1000\n",
      "282/282 [==============================] - 0s 282us/sample - loss: 0.0029\n",
      "Epoch 216/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0031\n",
      "Epoch 217/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0030\n",
      "Epoch 218/1000\n",
      "282/282 [==============================] - 0s 289us/sample - loss: 0.0035\n",
      "Epoch 219/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0032\n",
      "Epoch 220/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0032\n",
      "Epoch 221/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0034\n",
      "Epoch 222/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0036\n",
      "Epoch 223/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0037\n",
      "Epoch 224/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0032\n",
      "Epoch 225/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0033\n",
      "Epoch 226/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0031\n",
      "Epoch 227/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0035\n",
      "Epoch 228/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0037\n",
      "Epoch 229/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0035\n",
      "Epoch 230/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0035\n",
      "Epoch 231/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0035\n",
      "Epoch 232/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0033\n",
      "Epoch 233/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0033\n",
      "Epoch 234/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0035\n",
      "Epoch 235/1000\n",
      "282/282 [==============================] - 0s 259us/sample - loss: 0.0032\n",
      "Epoch 236/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0032\n",
      "Epoch 237/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0035\n",
      "Epoch 238/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0035\n",
      "Epoch 239/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0035\n",
      "Epoch 240/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0032\n",
      "Epoch 241/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0029\n",
      "Epoch 242/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0031\n",
      "Epoch 243/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0033\n",
      "Epoch 244/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0030\n",
      "Epoch 245/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0029\n",
      "Epoch 246/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0031\n",
      "Epoch 247/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0031\n",
      "Epoch 248/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0030\n",
      "Epoch 249/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0033\n",
      "Epoch 250/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0035\n",
      "Epoch 251/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0031\n",
      "Epoch 252/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0031\n",
      "Epoch 253/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0034\n",
      "Epoch 254/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0033\n",
      "Epoch 255/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0032\n",
      "Epoch 256/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0034\n",
      "Epoch 257/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0030\n",
      "Epoch 258/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0033\n",
      "Epoch 259/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0031\n",
      "Epoch 260/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0036\n",
      "Epoch 261/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0031\n",
      "Epoch 262/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0033\n",
      "Epoch 263/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0030\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0027\n",
      "Epoch 265/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0030\n",
      "Epoch 266/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0031\n",
      "Epoch 267/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0032\n",
      "Epoch 268/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0028\n",
      "Epoch 269/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0032\n",
      "Epoch 270/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0029\n",
      "Epoch 271/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0033\n",
      "Epoch 272/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0032\n",
      "Epoch 273/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0031\n",
      "Epoch 274/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0034\n",
      "Epoch 275/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0033\n",
      "Epoch 276/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0030\n",
      "Epoch 277/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0033\n",
      "Epoch 278/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0034\n",
      "Epoch 279/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0032\n",
      "Epoch 280/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 281/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0031\n",
      "Epoch 282/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0027\n",
      "Epoch 283/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0031\n",
      "Epoch 284/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0028\n",
      "Epoch 285/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0029\n",
      "Epoch 286/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0028\n",
      "Epoch 287/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0029\n",
      "Epoch 288/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0034\n",
      "Epoch 289/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0033\n",
      "Epoch 290/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0028\n",
      "Epoch 291/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0029\n",
      "Epoch 292/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0030\n",
      "Epoch 293/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0026\n",
      "Epoch 294/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0028\n",
      "Epoch 295/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0030\n",
      "Epoch 296/1000\n",
      "282/282 [==============================] - 0s 215us/sample - loss: 0.0027\n",
      "Epoch 297/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0028\n",
      "Epoch 298/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0027\n",
      "Epoch 299/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0032\n",
      "Epoch 300/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0032\n",
      "Epoch 301/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0028\n",
      "Epoch 302/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0029\n",
      "Epoch 303/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0029\n",
      "Epoch 304/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0026\n",
      "Epoch 305/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0028\n",
      "Epoch 306/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0032\n",
      "Epoch 307/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0031\n",
      "Epoch 308/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0032\n",
      "Epoch 309/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0031\n",
      "Epoch 310/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0033\n",
      "Epoch 311/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0027\n",
      "Epoch 312/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0030\n",
      "Epoch 313/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0028\n",
      "Epoch 314/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0030\n",
      "Epoch 315/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0027\n",
      "Epoch 316/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0029\n",
      "Epoch 317/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0031\n",
      "Epoch 318/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0031\n",
      "Epoch 319/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0033\n",
      "Epoch 320/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0030\n",
      "Epoch 321/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0027\n",
      "Epoch 322/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0025\n",
      "Epoch 323/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0028\n",
      "Epoch 324/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0027\n",
      "Epoch 325/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0028\n",
      "Epoch 326/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0028\n",
      "Epoch 327/1000\n",
      "282/282 [==============================] - 0s 214us/sample - loss: 0.0025\n",
      "Epoch 328/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0031\n",
      "Epoch 329/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 330/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0025\n",
      "Epoch 331/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0029\n",
      "Epoch 332/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0030\n",
      "Epoch 333/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0029\n",
      "Epoch 334/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0029\n",
      "Epoch 335/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0028\n",
      "Epoch 336/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0027\n",
      "Epoch 337/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 338/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0026\n",
      "Epoch 339/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0029\n",
      "Epoch 340/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0028\n",
      "Epoch 341/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0027\n",
      "Epoch 342/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0026\n",
      "Epoch 343/1000\n",
      "282/282 [==============================] - 0s 218us/sample - loss: 0.0027\n",
      "Epoch 344/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0026\n",
      "Epoch 345/1000\n",
      "282/282 [==============================] - 0s 224us/sample - loss: 0.0026\n",
      "Epoch 346/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0027\n",
      "Epoch 347/1000\n",
      "282/282 [==============================] - 0s 337us/sample - loss: 0.0027\n",
      "Epoch 348/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0025\n",
      "Epoch 349/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0027\n",
      "Epoch 350/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0026\n",
      "Epoch 351/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 352/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0027\n",
      "Epoch 353/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 354/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0028\n",
      "Epoch 355/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0030\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0031\n",
      "Epoch 357/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 358/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0027\n",
      "Epoch 359/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0030\n",
      "Epoch 360/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0027\n",
      "Epoch 361/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 362/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0027\n",
      "Epoch 363/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0024\n",
      "Epoch 364/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0025\n",
      "Epoch 365/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 366/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0023\n",
      "Epoch 367/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0028\n",
      "Epoch 368/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 369/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0025\n",
      "Epoch 370/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0027\n",
      "Epoch 371/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 372/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0024\n",
      "Epoch 373/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0026\n",
      "Epoch 374/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0024\n",
      "Epoch 375/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0027\n",
      "Epoch 376/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 377/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0025\n",
      "Epoch 378/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0024\n",
      "Epoch 379/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0025\n",
      "Epoch 380/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0029\n",
      "Epoch 381/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0032\n",
      "Epoch 382/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0028\n",
      "Epoch 383/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0031\n",
      "Epoch 384/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0034\n",
      "Epoch 385/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0027\n",
      "Epoch 386/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0024\n",
      "Epoch 387/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0027\n",
      "Epoch 388/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0025\n",
      "Epoch 389/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0025\n",
      "Epoch 390/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 391/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0026\n",
      "Epoch 392/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0030\n",
      "Epoch 393/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0023\n",
      "Epoch 394/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0026\n",
      "Epoch 395/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0027\n",
      "Epoch 396/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0029\n",
      "Epoch 397/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0025\n",
      "Epoch 398/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0024\n",
      "Epoch 399/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0023\n",
      "Epoch 400/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0026\n",
      "Epoch 401/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0028\n",
      "Epoch 402/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0026\n",
      "Epoch 403/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0026\n",
      "Epoch 404/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 405/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0028\n",
      "Epoch 406/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0026\n",
      "Epoch 407/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0028\n",
      "Epoch 408/1000\n",
      "282/282 [==============================] - 0s 219us/sample - loss: 0.0029\n",
      "Epoch 409/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0027\n",
      "Epoch 410/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0028\n",
      "Epoch 411/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0029\n",
      "Epoch 412/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0023\n",
      "Epoch 413/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 414/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0024\n",
      "Epoch 415/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0024\n",
      "Epoch 416/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0024\n",
      "Epoch 417/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0024\n",
      "Epoch 418/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 419/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0026\n",
      "Epoch 420/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0026\n",
      "Epoch 421/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0023\n",
      "Epoch 422/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0024\n",
      "Epoch 423/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0024\n",
      "Epoch 424/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0024\n",
      "Epoch 425/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0023\n",
      "Epoch 426/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0021\n",
      "Epoch 427/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0023\n",
      "Epoch 428/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0027\n",
      "Epoch 429/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0022\n",
      "Epoch 430/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0024\n",
      "Epoch 431/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0024\n",
      "Epoch 432/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0023\n",
      "Epoch 433/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0025\n",
      "Epoch 434/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0023\n",
      "Epoch 435/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0025\n",
      "Epoch 436/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0021\n",
      "Epoch 437/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0025\n",
      "Epoch 438/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0026\n",
      "Epoch 439/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0025\n",
      "Epoch 440/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0025\n",
      "Epoch 441/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0022\n",
      "Epoch 442/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0025\n",
      "Epoch 443/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0022\n",
      "Epoch 444/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0024\n",
      "Epoch 445/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0023\n",
      "Epoch 446/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0025\n",
      "Epoch 447/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0025\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0022\n",
      "Epoch 449/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0024\n",
      "Epoch 450/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0021\n",
      "Epoch 451/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0024\n",
      "Epoch 452/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0022\n",
      "Epoch 453/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0021\n",
      "Epoch 454/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0025\n",
      "Epoch 455/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0023\n",
      "Epoch 456/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0028\n",
      "Epoch 457/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0023\n",
      "Epoch 458/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0023\n",
      "Epoch 459/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0022\n",
      "Epoch 460/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0021\n",
      "Epoch 461/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0022\n",
      "Epoch 462/1000\n",
      "282/282 [==============================] - 0s 287us/sample - loss: 0.0023\n",
      "Epoch 463/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0022\n",
      "Epoch 464/1000\n",
      "282/282 [==============================] - 0s 283us/sample - loss: 0.0022\n",
      "Epoch 465/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0022\n",
      "Epoch 466/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0022\n",
      "Epoch 467/1000\n",
      "282/282 [==============================] - 0s 279us/sample - loss: 0.0022\n",
      "Epoch 468/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0024\n",
      "Epoch 469/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0026\n",
      "Epoch 470/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0024\n",
      "Epoch 471/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0022\n",
      "Epoch 472/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0021\n",
      "Epoch 473/1000\n",
      "282/282 [==============================] - 0s 256us/sample - loss: 0.0021\n",
      "Epoch 474/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0024\n",
      "Epoch 475/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0024\n",
      "Epoch 476/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0024\n",
      "Epoch 477/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0024\n",
      "Epoch 478/1000\n",
      "282/282 [==============================] - 0s 290us/sample - loss: 0.0024\n",
      "Epoch 479/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0021\n",
      "Epoch 480/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0024\n",
      "Epoch 481/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0023\n",
      "Epoch 482/1000\n",
      "282/282 [==============================] - 0s 269us/sample - loss: 0.0025\n",
      "Epoch 483/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0026\n",
      "Epoch 484/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0025\n",
      "Epoch 485/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0023\n",
      "Epoch 486/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0028\n",
      "Epoch 487/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0026\n",
      "Epoch 488/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0025\n",
      "Epoch 489/1000\n",
      "282/282 [==============================] - 0s 245us/sample - loss: 0.0027\n",
      "Epoch 490/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0024\n",
      "Epoch 491/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0024\n",
      "Epoch 492/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 493/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0025\n",
      "Epoch 494/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0028\n",
      "Epoch 495/1000\n",
      "282/282 [==============================] - 0s 213us/sample - loss: 0.0024\n",
      "Epoch 496/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0024\n",
      "Epoch 497/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 498/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 499/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0026\n",
      "Epoch 500/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0028\n",
      "Epoch 501/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0026\n",
      "Epoch 502/1000\n",
      "282/282 [==============================] - 0s 221us/sample - loss: 0.0029\n",
      "Epoch 503/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0027\n",
      "Epoch 504/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0029\n",
      "Epoch 505/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0026\n",
      "Epoch 506/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0020\n",
      "Epoch 507/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0024\n",
      "Epoch 508/1000\n",
      "282/282 [==============================] - 0s 263us/sample - loss: 0.0024\n",
      "Epoch 509/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0025\n",
      "Epoch 510/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0023\n",
      "Epoch 511/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0022\n",
      "Epoch 512/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0021\n",
      "Epoch 513/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0023\n",
      "Epoch 514/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0020\n",
      "Epoch 515/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0020\n",
      "Epoch 516/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0022\n",
      "Epoch 517/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0021\n",
      "Epoch 518/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0026\n",
      "Epoch 519/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0027\n",
      "Epoch 520/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0023\n",
      "Epoch 521/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0022\n",
      "Epoch 522/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0024\n",
      "Epoch 523/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0025\n",
      "Epoch 524/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0023\n",
      "Epoch 525/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0024\n",
      "Epoch 526/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0023\n",
      "Epoch 527/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0023\n",
      "Epoch 528/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0024\n",
      "Epoch 529/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0023\n",
      "Epoch 530/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0022\n",
      "Epoch 531/1000\n",
      "282/282 [==============================] - 0s 245us/sample - loss: 0.0022\n",
      "Epoch 532/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0022\n",
      "Epoch 533/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0022\n",
      "Epoch 534/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0023\n",
      "Epoch 535/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0020\n",
      "Epoch 536/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0024\n",
      "Epoch 537/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0024\n",
      "Epoch 538/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0026\n",
      "Epoch 539/1000\n",
      "282/282 [==============================] - 0s 278us/sample - loss: 0.0024\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0023\n",
      "Epoch 541/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0021\n",
      "Epoch 542/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0022\n",
      "Epoch 543/1000\n",
      "282/282 [==============================] - 0s 245us/sample - loss: 0.0023\n",
      "Epoch 544/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0024\n",
      "Epoch 545/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0022\n",
      "Epoch 546/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0023\n",
      "Epoch 547/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0022\n",
      "Epoch 548/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0021\n",
      "Epoch 549/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0022\n",
      "Epoch 550/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0023\n",
      "Epoch 551/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0019\n",
      "Epoch 552/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0019\n",
      "Epoch 553/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0020\n",
      "Epoch 554/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0022\n",
      "Epoch 555/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0022\n",
      "Epoch 556/1000\n",
      "282/282 [==============================] - 0s 261us/sample - loss: 0.0023\n",
      "Epoch 557/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0019\n",
      "Epoch 558/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0020\n",
      "Epoch 559/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 560/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0023\n",
      "Epoch 561/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 562/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0018\n",
      "Epoch 563/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0020\n",
      "Epoch 564/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0020\n",
      "Epoch 565/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 566/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0018\n",
      "Epoch 567/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0020\n",
      "Epoch 568/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0023\n",
      "Epoch 569/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0025\n",
      "Epoch 570/1000\n",
      "282/282 [==============================] - 0s 224us/sample - loss: 0.0024\n",
      "Epoch 571/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0022\n",
      "Epoch 572/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0020\n",
      "Epoch 573/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0021\n",
      "Epoch 574/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0020\n",
      "Epoch 575/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0024\n",
      "Epoch 576/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0020\n",
      "Epoch 577/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0022\n",
      "Epoch 578/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0021\n",
      "Epoch 579/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0023\n",
      "Epoch 580/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 581/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0022\n",
      "Epoch 582/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0020\n",
      "Epoch 583/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 584/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0020\n",
      "Epoch 585/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0022\n",
      "Epoch 586/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0022\n",
      "Epoch 587/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0021\n",
      "Epoch 588/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0020\n",
      "Epoch 589/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0022\n",
      "Epoch 590/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0022\n",
      "Epoch 591/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0020\n",
      "Epoch 592/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0020\n",
      "Epoch 593/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0021\n",
      "Epoch 594/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0021\n",
      "Epoch 595/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0020\n",
      "Epoch 596/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0021\n",
      "Epoch 597/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0022\n",
      "Epoch 598/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0023\n",
      "Epoch 599/1000\n",
      "282/282 [==============================] - 0s 288us/sample - loss: 0.0023\n",
      "Epoch 600/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0021\n",
      "Epoch 601/1000\n",
      "282/282 [==============================] - 0s 280us/sample - loss: 0.0019\n",
      "Epoch 602/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0022\n",
      "Epoch 603/1000\n",
      "282/282 [==============================] - 0s 294us/sample - loss: 0.0018\n",
      "Epoch 604/1000\n",
      "282/282 [==============================] - 0s 266us/sample - loss: 0.0018\n",
      "Epoch 605/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0019\n",
      "Epoch 606/1000\n",
      "282/282 [==============================] - 0s 296us/sample - loss: 0.0019\n",
      "Epoch 607/1000\n",
      "282/282 [==============================] - 0s 324us/sample - loss: 0.0019\n",
      "Epoch 608/1000\n",
      "282/282 [==============================] - 0s 256us/sample - loss: 0.0018\n",
      "Epoch 609/1000\n",
      "282/282 [==============================] - 0s 261us/sample - loss: 0.0017\n",
      "Epoch 610/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 611/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0020\n",
      "Epoch 612/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0016\n",
      "Epoch 613/1000\n",
      "282/282 [==============================] - 0s 256us/sample - loss: 0.0018\n",
      "Epoch 614/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0019\n",
      "Epoch 615/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0020\n",
      "Epoch 616/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0021\n",
      "Epoch 617/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 618/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0022\n",
      "Epoch 619/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0018\n",
      "Epoch 620/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0021\n",
      "Epoch 621/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0018\n",
      "Epoch 622/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0019\n",
      "Epoch 623/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0017\n",
      "Epoch 624/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0020\n",
      "Epoch 625/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 626/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0019\n",
      "Epoch 627/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0022\n",
      "Epoch 628/1000\n",
      "282/282 [==============================] - 0s 274us/sample - loss: 0.0021\n",
      "Epoch 629/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 630/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0021\n",
      "Epoch 631/1000\n",
      "282/282 [==============================] - 0s 268us/sample - loss: 0.0018\n",
      "Epoch 632/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0021\n",
      "Epoch 633/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0020\n",
      "Epoch 634/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0019\n",
      "Epoch 635/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0021\n",
      "Epoch 636/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0017\n",
      "Epoch 637/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0018\n",
      "Epoch 638/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0020\n",
      "Epoch 639/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0017\n",
      "Epoch 640/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 641/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0018\n",
      "Epoch 642/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0018\n",
      "Epoch 643/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0016\n",
      "Epoch 644/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0018\n",
      "Epoch 645/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0017\n",
      "Epoch 646/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0018\n",
      "Epoch 647/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0019\n",
      "Epoch 648/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0018\n",
      "Epoch 649/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0017\n",
      "Epoch 650/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0019\n",
      "Epoch 651/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0019\n",
      "Epoch 652/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0018\n",
      "Epoch 653/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0018\n",
      "Epoch 654/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0023\n",
      "Epoch 655/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0018\n",
      "Epoch 656/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0018\n",
      "Epoch 657/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0019\n",
      "Epoch 658/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0018\n",
      "Epoch 659/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0018\n",
      "Epoch 660/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0015\n",
      "Epoch 661/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 662/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0017\n",
      "Epoch 663/1000\n",
      "282/282 [==============================] - 0s 223us/sample - loss: 0.0019\n",
      "Epoch 664/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0020\n",
      "Epoch 665/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0019\n",
      "Epoch 666/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0019\n",
      "Epoch 667/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0025\n",
      "Epoch 668/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0027\n",
      "Epoch 669/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0025\n",
      "Epoch 670/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0020\n",
      "Epoch 671/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0020\n",
      "Epoch 672/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0018\n",
      "Epoch 673/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0020\n",
      "Epoch 674/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0019\n",
      "Epoch 675/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0020\n",
      "Epoch 676/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0017\n",
      "Epoch 677/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0016\n",
      "Epoch 678/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 679/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0014\n",
      "Epoch 680/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0016\n",
      "Epoch 681/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0016\n",
      "Epoch 682/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 683/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0021\n",
      "Epoch 684/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0023\n",
      "Epoch 685/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0020\n",
      "Epoch 686/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0018\n",
      "Epoch 687/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 688/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0021\n",
      "Epoch 689/1000\n",
      "282/282 [==============================] - 0s 265us/sample - loss: 0.0018\n",
      "Epoch 690/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0018\n",
      "Epoch 691/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0017\n",
      "Epoch 692/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0019\n",
      "Epoch 693/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0018\n",
      "Epoch 694/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0016\n",
      "Epoch 695/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0019\n",
      "Epoch 696/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0016\n",
      "Epoch 697/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 698/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0016\n",
      "Epoch 699/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0016\n",
      "Epoch 700/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0018\n",
      "Epoch 701/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0016\n",
      "Epoch 702/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0020\n",
      "Epoch 703/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 704/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0016\n",
      "Epoch 705/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0020\n",
      "Epoch 706/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0017\n",
      "Epoch 707/1000\n",
      "282/282 [==============================] - 0s 245us/sample - loss: 0.0019\n",
      "Epoch 708/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0019\n",
      "Epoch 709/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0018\n",
      "Epoch 710/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 711/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0019\n",
      "Epoch 712/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0018\n",
      "Epoch 713/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0017\n",
      "Epoch 714/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 715/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0020\n",
      "Epoch 716/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 717/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0016\n",
      "Epoch 718/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0019\n",
      "Epoch 719/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0018\n",
      "Epoch 720/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0018\n",
      "Epoch 721/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0017\n",
      "Epoch 722/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0018\n",
      "Epoch 723/1000\n",
      "282/282 [==============================] - 0s 256us/sample - loss: 0.0020\n",
      "Epoch 724/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0017\n",
      "Epoch 725/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0017\n",
      "Epoch 726/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0017\n",
      "Epoch 727/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0019\n",
      "Epoch 728/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0022\n",
      "Epoch 729/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0015\n",
      "Epoch 730/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0017\n",
      "Epoch 731/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0020\n",
      "Epoch 732/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0018\n",
      "Epoch 733/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 734/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 735/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0022\n",
      "Epoch 736/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0017\n",
      "Epoch 737/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0015\n",
      "Epoch 738/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0016\n",
      "Epoch 739/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0021\n",
      "Epoch 740/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0018\n",
      "Epoch 741/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0017\n",
      "Epoch 742/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0017\n",
      "Epoch 743/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0015\n",
      "Epoch 744/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0017\n",
      "Epoch 745/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0018\n",
      "Epoch 746/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0018\n",
      "Epoch 747/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0014\n",
      "Epoch 748/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0019\n",
      "Epoch 749/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0017\n",
      "Epoch 750/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0018\n",
      "Epoch 751/1000\n",
      "282/282 [==============================] - 0s 222us/sample - loss: 0.0019\n",
      "Epoch 752/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0019\n",
      "Epoch 753/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0018\n",
      "Epoch 754/1000\n",
      "282/282 [==============================] - 0s 275us/sample - loss: 0.0017\n",
      "Epoch 755/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0016\n",
      "Epoch 756/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0016\n",
      "Epoch 757/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0016\n",
      "Epoch 758/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0017\n",
      "Epoch 759/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0014\n",
      "Epoch 760/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0016\n",
      "Epoch 761/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0017\n",
      "Epoch 762/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0016\n",
      "Epoch 763/1000\n",
      "282/282 [==============================] - 0s 228us/sample - loss: 0.0014\n",
      "Epoch 764/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0014\n",
      "Epoch 765/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 766/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0013\n",
      "Epoch 767/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0013\n",
      "Epoch 768/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0015\n",
      "Epoch 769/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0015\n",
      "Epoch 770/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0017\n",
      "Epoch 771/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0016\n",
      "Epoch 772/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0019\n",
      "Epoch 773/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 774/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0020\n",
      "Epoch 775/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0018\n",
      "Epoch 776/1000\n",
      "282/282 [==============================] - 0s 263us/sample - loss: 0.0015\n",
      "Epoch 777/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0015\n",
      "Epoch 778/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0015\n",
      "Epoch 779/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 780/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0015\n",
      "Epoch 781/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 782/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 783/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0015\n",
      "Epoch 784/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 785/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0015\n",
      "Epoch 786/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0014\n",
      "Epoch 787/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 788/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0019\n",
      "Epoch 789/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0015\n",
      "Epoch 790/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0014\n",
      "Epoch 791/1000\n",
      "282/282 [==============================] - 0s 252us/sample - loss: 0.0016\n",
      "Epoch 792/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0015\n",
      "Epoch 793/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0015\n",
      "Epoch 794/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0015\n",
      "Epoch 795/1000\n",
      "282/282 [==============================] - 0s 254us/sample - loss: 0.0015\n",
      "Epoch 796/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0016\n",
      "Epoch 797/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0016\n",
      "Epoch 798/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0016\n",
      "Epoch 799/1000\n",
      "282/282 [==============================] - 0s 225us/sample - loss: 0.0017\n",
      "Epoch 800/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0013\n",
      "Epoch 801/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0013\n",
      "Epoch 802/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0016\n",
      "Epoch 803/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0018\n",
      "Epoch 804/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0013\n",
      "Epoch 805/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0015\n",
      "Epoch 806/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 807/1000\n",
      "282/282 [==============================] - 0s 271us/sample - loss: 0.0016\n",
      "Epoch 808/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0016\n",
      "Epoch 809/1000\n",
      "282/282 [==============================] - 0s 361us/sample - loss: 0.0013\n",
      "Epoch 810/1000\n",
      "282/282 [==============================] - 0s 332us/sample - loss: 0.0014\n",
      "Epoch 811/1000\n",
      "282/282 [==============================] - 0s 407us/sample - loss: 0.0015\n",
      "Epoch 812/1000\n",
      "282/282 [==============================] - 0s 396us/sample - loss: 0.0016\n",
      "Epoch 813/1000\n",
      "282/282 [==============================] - 0s 393us/sample - loss: 0.0014\n",
      "Epoch 814/1000\n",
      "282/282 [==============================] - 0s 315us/sample - loss: 0.0014\n",
      "Epoch 815/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0013\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0014\n",
      "Epoch 817/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0013\n",
      "Epoch 818/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0016\n",
      "Epoch 819/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 820/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0015\n",
      "Epoch 821/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0016\n",
      "Epoch 822/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0014\n",
      "Epoch 823/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0013\n",
      "Epoch 824/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0015\n",
      "Epoch 825/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 826/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0018\n",
      "Epoch 827/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0015\n",
      "Epoch 828/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0016\n",
      "Epoch 829/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0013\n",
      "Epoch 830/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0014\n",
      "Epoch 831/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0014\n",
      "Epoch 832/1000\n",
      "282/282 [==============================] - 0s 263us/sample - loss: 0.0014\n",
      "Epoch 833/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0013\n",
      "Epoch 834/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0016\n",
      "Epoch 835/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0014\n",
      "Epoch 836/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0016\n",
      "Epoch 837/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0014\n",
      "Epoch 838/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0015\n",
      "Epoch 839/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 840/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0015\n",
      "Epoch 841/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0017\n",
      "Epoch 842/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0015\n",
      "Epoch 843/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0018\n",
      "Epoch 844/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0017\n",
      "Epoch 845/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0020\n",
      "Epoch 846/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0017\n",
      "Epoch 847/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0018\n",
      "Epoch 848/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0016\n",
      "Epoch 849/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 850/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0014\n",
      "Epoch 851/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0016\n",
      "Epoch 852/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0014\n",
      "Epoch 853/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0013\n",
      "Epoch 854/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0012\n",
      "Epoch 855/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0014\n",
      "Epoch 856/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0011\n",
      "Epoch 857/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0013\n",
      "Epoch 858/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0016\n",
      "Epoch 859/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 860/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0013\n",
      "Epoch 861/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0015\n",
      "Epoch 862/1000\n",
      "282/282 [==============================] - 0s 242us/sample - loss: 0.0012\n",
      "Epoch 863/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0013\n",
      "Epoch 864/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 865/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0017\n",
      "Epoch 866/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0017\n",
      "Epoch 867/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0014\n",
      "Epoch 868/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0014\n",
      "Epoch 869/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0014\n",
      "Epoch 870/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0014\n",
      "Epoch 871/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0014\n",
      "Epoch 872/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0013\n",
      "Epoch 873/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0013\n",
      "Epoch 874/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0013\n",
      "Epoch 875/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0015\n",
      "Epoch 876/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0016\n",
      "Epoch 877/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0014\n",
      "Epoch 878/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0012\n",
      "Epoch 879/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0013\n",
      "Epoch 880/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0011\n",
      "Epoch 881/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0014\n",
      "Epoch 882/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0013\n",
      "Epoch 883/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0015\n",
      "Epoch 884/1000\n",
      "282/282 [==============================] - 0s 227us/sample - loss: 0.0013\n",
      "Epoch 885/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0013\n",
      "Epoch 886/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0013\n",
      "Epoch 887/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0013\n",
      "Epoch 888/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0015\n",
      "Epoch 889/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0014\n",
      "Epoch 890/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0014\n",
      "Epoch 891/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 892/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0015\n",
      "Epoch 893/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0014\n",
      "Epoch 894/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0016\n",
      "Epoch 895/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0017\n",
      "Epoch 896/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0015\n",
      "Epoch 897/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0013\n",
      "Epoch 898/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0014\n",
      "Epoch 899/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 900/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0015\n",
      "Epoch 901/1000\n",
      "282/282 [==============================] - 0s 249us/sample - loss: 0.0016\n",
      "Epoch 902/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 903/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0015\n",
      "Epoch 904/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 905/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0017\n",
      "Epoch 906/1000\n",
      "282/282 [==============================] - 0s 246us/sample - loss: 0.0017\n",
      "Epoch 907/1000\n",
      "282/282 [==============================] - 0s 226us/sample - loss: 0.0016\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 909/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0016\n",
      "Epoch 910/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0015\n",
      "Epoch 911/1000\n",
      "282/282 [==============================] - 0s 218us/sample - loss: 0.0015\n",
      "Epoch 912/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0015\n",
      "Epoch 913/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0015\n",
      "Epoch 914/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0014\n",
      "Epoch 915/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0013\n",
      "Epoch 916/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0015\n",
      "Epoch 917/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0015\n",
      "Epoch 918/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0014\n",
      "Epoch 919/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0013\n",
      "Epoch 920/1000\n",
      "282/282 [==============================] - 0s 264us/sample - loss: 0.0014\n",
      "Epoch 921/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0011\n",
      "Epoch 922/1000\n",
      "282/282 [==============================] - 0s 253us/sample - loss: 0.0011\n",
      "Epoch 923/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0011\n",
      "Epoch 924/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0012\n",
      "Epoch 925/1000\n",
      "282/282 [==============================] - 0s 262us/sample - loss: 0.0012\n",
      "Epoch 926/1000\n",
      "282/282 [==============================] - 0s 231us/sample - loss: 0.0013\n",
      "Epoch 927/1000\n",
      "282/282 [==============================] - 0s 229us/sample - loss: 0.0014\n",
      "Epoch 928/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0012\n",
      "Epoch 929/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0014\n",
      "Epoch 930/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0013\n",
      "Epoch 931/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0012\n",
      "Epoch 932/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 933/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0016\n",
      "Epoch 934/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 935/1000\n",
      "282/282 [==============================] - 0s 330us/sample - loss: 0.0015\n",
      "Epoch 936/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0013\n",
      "Epoch 937/1000\n",
      "282/282 [==============================] - 0s 241us/sample - loss: 0.0014\n",
      "Epoch 938/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0013\n",
      "Epoch 939/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0014\n",
      "Epoch 940/1000\n",
      "282/282 [==============================] - 0s 238us/sample - loss: 0.0014\n",
      "Epoch 941/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0014\n",
      "Epoch 942/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0015\n",
      "Epoch 943/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0015\n",
      "Epoch 944/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0015\n",
      "Epoch 945/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0014\n",
      "Epoch 946/1000\n",
      "282/282 [==============================] - 0s 235us/sample - loss: 0.0014\n",
      "Epoch 947/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0012\n",
      "Epoch 948/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0015\n",
      "Epoch 949/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0015\n",
      "Epoch 950/1000\n",
      "282/282 [==============================] - 0s 257us/sample - loss: 0.0017\n",
      "Epoch 951/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0019\n",
      "Epoch 952/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0018\n",
      "Epoch 953/1000\n",
      "282/282 [==============================] - 0s 258us/sample - loss: 0.0015\n",
      "Epoch 954/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0014\n",
      "Epoch 955/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 956/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0012\n",
      "Epoch 957/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0015\n",
      "Epoch 958/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0010\n",
      "Epoch 959/1000\n",
      "282/282 [==============================] - 0s 276us/sample - loss: 0.0014\n",
      "Epoch 960/1000\n",
      "282/282 [==============================] - 0s 340us/sample - loss: 0.0014\n",
      "Epoch 961/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0011\n",
      "Epoch 962/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0011\n",
      "Epoch 963/1000\n",
      "282/282 [==============================] - 0s 251us/sample - loss: 0.0011\n",
      "Epoch 964/1000\n",
      "282/282 [==============================] - 0s 234us/sample - loss: 0.0014\n",
      "Epoch 965/1000\n",
      "282/282 [==============================] - 0s 268us/sample - loss: 0.0014\n",
      "Epoch 966/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0014\n",
      "Epoch 967/1000\n",
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0013\n",
      "Epoch 968/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0013\n",
      "Epoch 969/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0011\n",
      "Epoch 970/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 971/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0013\n",
      "Epoch 972/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0014\n",
      "Epoch 973/1000\n",
      "282/282 [==============================] - 0s 237us/sample - loss: 0.0016\n",
      "Epoch 974/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0016\n",
      "Epoch 975/1000\n",
      "282/282 [==============================] - 0s 247us/sample - loss: 0.0013\n",
      "Epoch 976/1000\n",
      "282/282 [==============================] - 0s 239us/sample - loss: 0.0012\n",
      "Epoch 977/1000\n",
      "282/282 [==============================] - 0s 272us/sample - loss: 0.0013\n",
      "Epoch 978/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0012\n",
      "Epoch 979/1000\n",
      "282/282 [==============================] - 0s 230us/sample - loss: 0.0012\n",
      "Epoch 980/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0012\n",
      "Epoch 981/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0012\n",
      "Epoch 982/1000\n",
      "282/282 [==============================] - 0s 255us/sample - loss: 0.0012\n",
      "Epoch 983/1000\n",
      "282/282 [==============================] - 0s 232us/sample - loss: 0.0012\n",
      "Epoch 984/1000\n",
      "282/282 [==============================] - 0s 250us/sample - loss: 0.0013\n",
      "Epoch 985/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0011\n",
      "Epoch 986/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0013\n",
      "Epoch 987/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0016\n",
      "Epoch 988/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0013\n",
      "Epoch 989/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0012\n",
      "Epoch 990/1000\n",
      "282/282 [==============================] - 0s 243us/sample - loss: 0.0011\n",
      "Epoch 991/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0011\n",
      "Epoch 992/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0012\n",
      "Epoch 993/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0014\n",
      "Epoch 994/1000\n",
      "282/282 [==============================] - 0s 240us/sample - loss: 0.0014\n",
      "Epoch 995/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0014\n",
      "Epoch 996/1000\n",
      "282/282 [==============================] - 0s 236us/sample - loss: 0.0013\n",
      "Epoch 997/1000\n",
      "282/282 [==============================] - 0s 233us/sample - loss: 0.0013\n",
      "Epoch 998/1000\n",
      "282/282 [==============================] - 0s 220us/sample - loss: 0.0013\n",
      "Epoch 999/1000\n",
      "282/282 [==============================] - 0s 244us/sample - loss: 0.0011\n",
      "Epoch 1000/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 248us/sample - loss: 0.0012\n",
      "\n",
      "==========================\n",
      "MAE= [2.100564]\n",
      "RMSE =  3.6247822926358415\n",
      "NMSE =  [0.00911511]\n",
      "MAPE= [0.01019301]\n",
      "IA= [0.9580713]\n",
      "U1= 0.008507888561311829\n",
      "U2= 0.6887017727039924\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 75 seconds\n"
     ]
    }
   ],
   "source": [
    "#Bi-LSTM-SED\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import merge\n",
    "from tensorflow.python.keras.layers.merge import Multiply\n",
    "from tensorflow.python.keras.layers.core import *\n",
    "from tensorflow.python.keras.models import *\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.layers import Input,Dense,Reshape,Dropout, Embedding, LSTM, Bidirectional,Permute\n",
    "from tensorflow.python.keras.layers import RepeatVector, TimeDistributed\n",
    "from tensorflow.python.keras.layers.recurrent import GRU\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import concat, read_csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as skm\n",
    "import math\n",
    "from math import sqrt\n",
    "import time\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "#1. load dataset\n",
    "dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-CEEMDAN-BDX2.csv', engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "data = dataset.reshape(-1,6)\n",
    "\n",
    "\n",
    "timestep = 6\n",
    "dim = 2\n",
    "\n",
    "#数据缩放 拆分输入X（7维）&输出Y（1维）\n",
    "X = dataset[:,0:2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for i in range(dim):\n",
    "    Xdata = X[:,i]\n",
    "    Xdata = Xdata.reshape(-1,1)\n",
    "    Xdata = scaler.fit_transform(Xdata)\n",
    "    Xdata = Xdata.flatten()\n",
    "    X[:,i] = Xdata\n",
    "X_scaler = X.reshape(324,-1)\n",
    "print(X_scaler.shape)\n",
    "\n",
    "Y = dataset[:,0]\n",
    "Y_scaler= (Y-np.min(Y))/(np.max(Y)-np.min(Y))\n",
    "Y_scaler = Y_scaler.reshape(-1)\n",
    "print(Y_scaler.shape)\n",
    "\n",
    "\n",
    "#重构数据集\n",
    "##timestep为时间步长\n",
    "def create_X(seq, timestep):\n",
    "    dataX = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        a = seq[i:(i+timestep)]\n",
    "        # X按照顺序取值 每次在后面增加一个数据\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "def create_Y(seq, timestep):\n",
    "    dataY = []\n",
    "    for i in range(len(seq)-timestep):\n",
    "        # Y向后移动一位取值\n",
    "        dataY.append(seq[i+timestep])\n",
    "    return np.array(dataY)\n",
    "\n",
    "\n",
    "\n",
    "def get_bilstm_model():\n",
    "    K.clear_session() #清除之前的模型，省得压满内存\n",
    "    inputs = Input(shape=(timestep, dim,))\n",
    "    lstm_units1 = 6\n",
    "    lstm_units2 = 36\n",
    "    bilstm_out1 = Bidirectional(LSTM(lstm_units1,return_sequences=True),merge_mode='concat')(inputs)\n",
    "    bilstm_out2 = LSTM(lstm_units2, return_sequences=True)(bilstm_out1)\n",
    "    dropout_out = Dropout(0.5)(bilstm_out2)\n",
    "    bilstm_out = Flatten()(dropout_out)\n",
    "    output = Dense(1, activation='relu')(bilstm_out)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#预测\n",
    "pres=[]\n",
    "# 将数据拆分成训练和测试，7/9作为训练数据\n",
    "train_size = int(len(dataset) * 0.89)\n",
    "test_size = len(dataset) - train_size\n",
    "trainX, testX = X_scaler[0:train_size], X_scaler[train_size:len(dataset)]\n",
    "trainY, testY = Y_scaler[0:train_size], Y_scaler[train_size:len(dataset)]\n",
    "print(\"原始训练集的长度：\",train_size)\n",
    "print(\"原始测试集的长度：\",test_size)\n",
    "#print(trainX,trainX.shape)\n",
    "#print(trainY,trainY.shape)\n",
    "#print(testX,testX.shape)\n",
    "#print(testY,testY.shape)\n",
    "\n",
    "train_X=create_X(trainX,timestep)#(246,6)\n",
    "#print(train_X,train_X.shape)\n",
    "train_Y=create_Y(trainY,timestep)#(246,)\n",
    "#print(train_Y,train_Y.shape)\n",
    "test_X=create_X(testX,timestep)#(66,6,6)\n",
    "#print(test_X,test_X.shape)\n",
    "test_Y=create_Y(testY,timestep)#(66,)\n",
    "#print(test_Y,test_Y.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    model = get_bilstm_model()\n",
    "    optimizer = Adam(0.01)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.fit(train_X, train_Y, epochs=1000, batch_size=64)\n",
    "\n",
    "    # 开始预测\n",
    "    trainPredict = model.predict(train_X)\n",
    "    testPredict = model.predict(test_X)\n",
    "    \n",
    "    # 逆缩放预测值\n",
    "    #PD-TVFEMD-BDX:  0-BDX. 2-BDX. 53-BDX. 54-BDX. 70-BDX. 72-BDX\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD-TVFEMD-BDX.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#tvfemd分解BDX数据\n",
    "    \n",
    "    #trainPre = trainPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    #trainPre = trainPre.reshape(-1)\n",
    "    #trainPrebdx =pd.DataFrame(trainPre)\n",
    "    #trainPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmbdx_train.csv', header=False)\n",
    "    \n",
    "    testPre = testPredict*((np.max(Y)-np.min(Y)))+np.min(Y)\n",
    "    testPre = testPre.reshape(-1)\n",
    "    #testPrebdx =pd.DataFrame(testPre)#备份成表格输出\n",
    "    #testPrebdx.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmbdx_test.csv', header=False)\n",
    "    \n",
    "    \n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/QSX.csv', usecols=[0], engine='python')\n",
    "    QSX = dataframe.values\n",
    "    QSX = QSX.astype('float32')\n",
    "    QSX = QSX[train_size+timestep:len(dataset)]#测试集的Y的tvfemd分解QSX\n",
    "    QSX = QSX.reshape(-1)\n",
    "    dataframe = read_csv('C:/Users/Administrator/Desktop/XI-2/data/try2ed/PD.csv', usecols=[0], engine='python')\n",
    "    Y = dataframe.values\n",
    "    Y = Y.astype('float32')#原始数据\n",
    "    testY_ori = Y[train_size+timestep:len(dataset)]#测试集\n",
    "    testY_ori = testY_ori.reshape((-1,1))\n",
    "    for i in range(len(testY_ori)):\n",
    "        testPredict[i]=QSX[i] + testPre[i]\n",
    "    testPredict = testPredict.reshape(-1)\n",
    "\n",
    "    \n",
    "    #误差计算\n",
    "    error = []#Y-Y'\n",
    "    error1= []#abs((Y-Y')/Y)\n",
    "    error2= []#Y*Y'\n",
    "    squared1 =[]#Y*Y\n",
    "    squared2 =[]#Y'*Y'\n",
    "    for i in range(len(testY_ori)):\n",
    "        error.append(testY_ori[i] - testPredict[i])\n",
    "        error1.append(abs((testY_ori[i] - testPredict[i])/testY_ori[i]))\n",
    "        error2.append(testY_ori[i]*testPredict[i])\n",
    "        squared1.append(testY_ori[i]*testY_ori[i])\n",
    "        squared2.append(testPredict[i]*testPredict[i])\n",
    "        \n",
    "        \n",
    "    squaredError = []#(Y-Y')^2\n",
    "    absError = []#abs(Y-Y')\n",
    "    for val in error:    \n",
    "        squaredError.append(val * val)#target-prediction之差平方     \n",
    "        absError.append(abs(val))#误差绝对值\n",
    "        \n",
    "    MSE=sum(squaredError) / len(squaredError)\n",
    "    meannn=np.mean(testY_ori)\n",
    "    NMSEerror = []\n",
    "    IAerror = []\n",
    "    for i in range(len(testY_ori)):\n",
    "        NMSEerror.append(squaredError[i]/error2[i])\n",
    "        IAerror.append((abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn))*(abs(testY_ori[i] - meannn)+abs(testPredict[i] - meannn)))\n",
    "    \n",
    "    U2error1 = []\n",
    "    U2error2 = []\n",
    "    for i in range(len(testY_ori)-1):\n",
    "        U2error1.append(((testY_ori[i+1] - testPredict[i+1])/testY_ori[i])*((testY_ori[i+1] - testPredict[i+1])/testY_ori[i]))\n",
    "        U2error2.append(((testY_ori[i+1] - testPredict[i])/testY_ori[i])*((testY_ori[i+1] - testPredict[i])/testY_ori[i]))\n",
    "    print('\\n==========================')\n",
    "    MAE=sum(absError)/len(absError)\n",
    "    print('MAE=',MAE)\n",
    "    from math import sqrt\n",
    "    RMSE=sqrt(MSE)\n",
    "    print(\"RMSE = \", RMSE)#均方根误差RMSE\n",
    "    NMSE=sum(NMSEerror)\n",
    "    print(\"NMSE = \", NMSE)#误差平方的归一化平均值NMSE\n",
    "    MAPE=sum(error1)/len(error1)\n",
    "    print('MAPE=',MAPE)\n",
    "    IA=1-sum(squaredError)/sum(IAerror)\n",
    "    print('IA=',IA)#一致性指数\n",
    "    U1index=RMSE/(sqrt(sum(squared1)/len(squared1))+sqrt(sum(squared2)/len(squared2)))\n",
    "    print('U1=',U1index)\n",
    "    U2index=(sqrt(sum(U2error1)/len(testY_ori)))/(sqrt(sum(U2error2)/len(testY_ori)))\n",
    "    print('U2=',U2index)\n",
    "\n",
    "    #输出结果\n",
    "    testPredict=testPredict.reshape(-1)\n",
    "    testPredict=pd.DataFrame(testPredict)\n",
    "    testPredict.to_csv('C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmoutput.csv', header=False)\n",
    "    import csv\n",
    "    Evaluation_index = [MAE,RMSE,NMSE,MAPE,IA,U1index,U2index]\n",
    "    with open(\"C:/Users/Administrator/Desktop/XI-2/data/pre_result/lstmEvaluation.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file ,delimiter=',')\n",
    "        writer.writerow(Evaluation_index)\n",
    "    \n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(testPredict,color='green', label='Predict')\n",
    "    plt.plot(testY_ori,color='pink', label='Original')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    pres.append(testPredict)\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))\n",
    "\n",
    "#Bi-LSTM-SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}